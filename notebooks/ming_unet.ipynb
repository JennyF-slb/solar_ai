{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t1t0pigyntSp",
        "3TxK2hAZpWo9"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Create Colab Notebook folder\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ln -s \"/gdrive/My Drive/Colab Notebooks\" \"/content/Colab Notebooks\"\n",
        "\n",
        "# Put Colab in the context of the project\n",
        "import os\n",
        "# os.chdir allows you to change directories, like cd in the Terminal\n",
        "os.chdir('/content/Colab Notebooks/AerialImageDataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMhEyIc4n10-",
        "outputId": "59fe8169-7b1e-4c14-d015-5055b814ec62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFSPEXg3rlOg",
        "outputId": "7b55288b-b17c-4f5b-9970-4574ef04b7b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "# from osgeo import gdal\n",
        "# import rasterio\n",
        "import shutil\n",
        "from types import MethodType\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate,ZeroPadding2D , UpSampling2D,Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:35:41.992926Z",
          "iopub.execute_input": "2023-05-24T11:35:41.993711Z",
          "iopub.status.idle": "2023-05-24T11:35:48.606734Z",
          "shell.execute_reply.started": "2023-05-24T11:35:41.993672Z",
          "shell.execute_reply": "2023-05-24T11:35:48.605542Z"
        },
        "trusted": true,
        "id": "9rMqA1tYntSi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if TensorFlow is using GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        print(f\"GPU Device Name: {device.name}\")\n",
        "else:\n",
        "    print(\"No GPU devices found. Make sure TensorFlow GPU is properly installed.\")\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(\"TensorFlow Version:\", tf.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:35:48.608756Z",
          "iopub.execute_input": "2023-05-24T11:35:48.609648Z",
          "iopub.status.idle": "2023-05-24T11:35:48.795395Z",
          "shell.execute_reply.started": "2023-05-24T11:35:48.609609Z",
          "shell.execute_reply": "2023-05-24T11:35:48.794037Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qihayQqEntSi",
        "outputId": "7ecef20c-dd4a-415f-b1f0-94184b6db3d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device Name: /physical_device:GPU:0\n",
            "TensorFlow Version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PYTHONHASHSEED\"] = str(23)\n",
        "np.random.seed(23)\n",
        "tf.random.set_seed(23)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:35:48.797511Z",
          "iopub.execute_input": "2023-05-24T11:35:48.798069Z",
          "iopub.status.idle": "2023-05-24T11:35:48.805121Z",
          "shell.execute_reply.started": "2023-05-24T11:35:48.798029Z",
          "shell.execute_reply": "2023-05-24T11:35:48.803976Z"
        },
        "trusted": true,
        "id": "eLf28tKintSj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jXTxDgGls6x5",
        "outputId": "52761c60-e70e-4b0b-f891-d7974e6699c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/aerialimage"
      ],
      "metadata": {
        "id": "j0fnVF_vax5H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSVQMB42ZZ_T",
        "outputId": "38082a86-1aab-4ffe-fa96-192c441dffe2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " aerialimage  'Colab Notebooks'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folders to move train and validation files\n",
        "\n",
        "!mkdir /content/aerialimage/train_input\n",
        "!mkdir /content/aerialimage/train_target\n",
        "\n",
        "!mkdir /content/aerialimage/val_input\n",
        "!mkdir /content/aerialimage/val_target"
      ],
      "metadata": {
        "id": "TpnJrCICAj3M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folders to move train and validation files\n",
        "\n",
        "!mkdir /content/aerialimage/train_input/input_data\n",
        "!mkdir /content/aerialimage/train_target/target_data\n",
        "\n",
        "!mkdir /content/aerialimage/val_input/input_data\n",
        "!mkdir /content/aerialimage/val_target/target_data"
      ],
      "metadata": {
        "id": "GRRLBOc5AsqJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move input images to the folder\n",
        "\n",
        "org_train_input = '/content/Colab Notebooks/AerialImageDataset/train/images'\n",
        "new_train_input = '/content/aerialimage/train_input/input_data'\n",
        "new_val_input = '/content/aerialimage/val_input/input_data'\n",
        "\n",
        "input_img_paths = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(org_train_input):\n",
        "    for filename in filenames:\n",
        "        input_img_paths.append(os.path.join(dirname, filename))\n",
        "\n",
        "input_img_paths = sorted(input_img_paths)\n",
        "\n",
        "random.Random(23).shuffle(input_img_paths)\n",
        "    \n",
        "input_img_paths[0:2]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:35:48.816778Z",
          "iopub.execute_input": "2023-05-24T11:35:48.818122Z",
          "iopub.status.idle": "2023-05-24T11:35:48.834229Z",
          "shell.execute_reply.started": "2023-05-24T11:35:48.818087Z",
          "shell.execute_reply": "2023-05-24T11:35:48.833355Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEFZpUEgntSk",
        "outputId": "09280307-8922-4c74-af09-b9e07df44be8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Colab Notebooks/AerialImageDataset/train/images/chicago5.tif',\n",
              " '/content/Colab Notebooks/AerialImageDataset/train/images/kitsap13.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_num = 40 ## 20% of train dataset \n",
        "\n",
        "for file in input_img_paths[:val_num]:\n",
        "    shutil.copy(file, new_val_input)\n",
        "    \n",
        "for file in input_img_paths[val_num:]:\n",
        "    shutil.copy(file, new_train_input)"
      ],
      "metadata": {
        "id": "EbtlHJS-usmi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move target images to the folder\n",
        "\n",
        "org_train_target = '/content/Colab Notebooks/AerialImageDataset/train/gt'\n",
        "new_train_target = '/content/aerialimage/train_target/target_data'\n",
        "new_val_target = '/content/aerialimage/val_target/target_data'\n",
        "\n",
        "target_img_paths = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(org_train_target):\n",
        "    for filename in filenames:\n",
        "        target_img_paths.append(os.path.join(dirname, filename))\n",
        "\n",
        "target_img_paths = sorted(target_img_paths)\n",
        "\n",
        "random.Random(23).shuffle(target_img_paths)\n",
        "\n",
        "target_img_paths[0:2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:40:00.228519Z",
          "iopub.execute_input": "2023-05-24T11:40:00.231459Z",
          "iopub.status.idle": "2023-05-24T11:40:00.251953Z",
          "shell.execute_reply.started": "2023-05-24T11:40:00.231412Z",
          "shell.execute_reply": "2023-05-24T11:40:00.250617Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IruLGKKyntSl",
        "outputId": "92207fa7-a95d-4c50-e897-bde3f4395e2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Colab Notebooks/AerialImageDataset/train/gt/chicago5.tif',\n",
              " '/content/Colab Notebooks/AerialImageDataset/train/gt/kitsap13.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy 40 target images to validation folder\n",
        "\n",
        "for file in target_img_paths[:val_num]:\n",
        "    shutil.copy(file, new_val_target)\n",
        "    \n",
        "for file in target_img_paths[val_num:]:\n",
        "    shutil.copy(file, new_train_target)"
      ],
      "metadata": {
        "id": "xop-J5fuFAbe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an image generator / data augmentation pipeline \n",
        "# augment data in train dataset only\n",
        "\n",
        "BATCH_SIZE = 5\n",
        "TARGET_SIZE = (256,256)\n",
        "seed = 23\n",
        "# patch_size = (500, 500)  # Specify the desired patch size\n",
        "# overlap = 250  # Specify the desired overlap size, 50% for this case\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   samplewise_std_normalization=False, \n",
        "                                   horizontal_flip = True, \n",
        "                                   vertical_flip = False, # 1st run : False, 2nd run: True\n",
        "                                   height_shift_range = 0.1, \n",
        "                                   width_shift_range = 0.1, \n",
        "                                   rotation_range = 3, # 1st run : 3, 2nd run:10\n",
        "                                   shear_range = 0.01, # 1st run : 0.01, 2nd run: 0.1\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   zoom_range = 0.05, #1st run 0.05, 2nd run: 0.1\n",
        "                                   zca_whitening = True,\n",
        "                                   zca_epsilon=1e-5, \n",
        "#                                    preprocessing_function=patch_image,\n",
        "                                   )\n",
        "\n",
        "\n",
        "target_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   samplewise_std_normalization=False, \n",
        "                                   horizontal_flip = True, \n",
        "                                   vertical_flip = False, # 1st run : False, 2nd run: True\n",
        "                                   height_shift_range = 0.1, \n",
        "                                   width_shift_range = 0.1, \n",
        "                                   rotation_range = 3, # 1st run : 3, 2nd run:10\n",
        "                                   shear_range = 0.01, # 1st run : 0.01, 2nd run: 0.1\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   zoom_range = 0.05, #1st run 0.05, 2nd run: 0.1\n",
        "                                   zca_whitening = True,\n",
        "                                   zca_epsilon=1e-5, \n",
        "#                                    preprocessing_function=patch_image\n",
        "                                   )\n",
        "\n",
        "val_input_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_target_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:47:34.019319Z",
          "iopub.execute_input": "2023-05-24T11:47:34.020013Z",
          "iopub.status.idle": "2023-05-24T11:47:34.029973Z",
          "shell.execute_reply.started": "2023-05-24T11:47:34.019952Z",
          "shell.execute_reply": "2023-05-24T11:47:34.028864Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2dqti1ontSn",
        "outputId": "396d42ee-abee-46c1-b6ab-d3b879f568d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use data augmentation pipeline and start loading train data from folders\n",
        "# TARGET_SIZE = (512,512)\n",
        "\n",
        "train_generator_input = train_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/train_input',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    seed = seed\n",
        "\n",
        ")\n",
        "\n",
        "train_generator_output = target_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/train_target',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    seed = seed\n",
        ")\n",
        "\n",
        "train_generator = zip(train_generator_input, train_generator_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:47:40.854450Z",
          "iopub.execute_input": "2023-05-24T11:47:40.854845Z",
          "iopub.status.idle": "2023-05-24T11:47:40.882939Z",
          "shell.execute_reply.started": "2023-05-24T11:47:40.854812Z",
          "shell.execute_reply": "2023-05-24T11:47:40.881994Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc_2d6LLntSn",
        "outputId": "6a1c2e06-235f-46d0-802f-7a5fa488df62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140 images belonging to 1 classes.\n",
            "Found 140 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use data augmentation pipeline and start loading validation data from folders\n",
        "\n",
        "val_generator_input = val_input_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/val_input',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    seed = seed\n",
        "\n",
        ")\n",
        "\n",
        "val_generator_output = val_target_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/val_target',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    seed = seed\n",
        ")\n",
        "\n",
        "val_generator = zip(val_generator_input, val_generator_output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:47:43.061294Z",
          "iopub.execute_input": "2023-05-24T11:47:43.061938Z",
          "iopub.status.idle": "2023-05-24T11:47:43.082973Z",
          "shell.execute_reply.started": "2023-05-24T11:47:43.061900Z",
          "shell.execute_reply": "2023-05-24T11:47:43.082032Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQGuCdIDntSn",
        "outputId": "a2c077cc-1a2a-4f78-ae17-37b72500fe47"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 images belonging to 1 classes.\n",
            "Found 40 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Patching"
      ],
      "metadata": {
        "id": "S5QpAgfRm3eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_patches(image, patch_size, overlap): #image is image array with dimention, e.g, (5000,5000,3). patch_size is 2d. overlap is a number\n",
        "    height, width = image.shape[:2]    \n",
        "    patch_height, patch_width = patch_size\n",
        "    \n",
        "    stride_height = patch_height - overlap\n",
        "    stride_width = patch_width - overlap\n",
        "    \n",
        "    patches = []\n",
        "    \n",
        "    for y in range(0, height-patch_height+1, stride_height):\n",
        "        for x in range(0, width-patch_width+1, stride_width):\n",
        "            patch = image[y:y+patch_height, x:x+patch_width]\n",
        "            patches.append(patch)\n",
        "    \n",
        "    return patches   #return all patches"
      ],
      "metadata": {
        "id": "hDT2ZRMgcEYy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/aerialimage/train_patches\n",
        "!mkdir /content/aerialimage/train_targetpatches\n",
        "!mkdir /content/aerialimage/test_patches\n",
        "!mkdir /content/aerialimage/val_patches\n",
        "!mkdir /content/aerialimage/val_targetpatches"
      ],
      "metadata": {
        "id": "ZRyetYK1dQik"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shutil.rmtree('/content/aerialimage/train_patches/gt_patches')"
      ],
      "metadata": {
        "id": "2M2nVtn9rxb-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/aerialimage/train_patches/images_patches\n",
        "!mkdir /content/aerialimage/train_targetpatches/gt_patches\n",
        "!mkdir /content/aerialimage/test_patches/images_patches\n",
        "!mkdir /content/aerialimage/val_patches/images_patches\n",
        "!mkdir /content/aerialimage/val_targetpatches/gt_patches"
      ],
      "metadata": {
        "id": "s1RwKPTDdimo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training patches"
      ],
      "metadata": {
        "id": "tevbYkFf04kD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Specify the absolute path to the \"aerialimage\" folder\n",
        "absolute_path = '/content/aerialimage'\n",
        "\n",
        "# Construct the absolute path to the \"train/images\" directory for reading\n",
        "train_images_dir = new_train_input\n",
        "\n",
        "# Retrieve a list of files in the \"train/images\" directory\n",
        "files = os.listdir(train_images_dir)\n",
        "\n",
        "# Filter files based on criteria (e.g., file extension)\n",
        "image_files = [file for file in sorted(files) if file.endswith('.tif')]\n",
        "\n",
        "# Construct the relative path to the \"train_patches\" directory for writing\n",
        "train_images_patches_dir = os.path.join(absolute_path, 'train_patches/images_patches')\n",
        "train_gt_patches_dir = os.path.join(absolute_path, 'train_targetpatches/gt_patches')\n",
        "\n",
        "# Construct the relative path to the \"test_patches\" directory for writing\n",
        "test_images_patches_dir = os.path.join(absolute_path, 'test_patches/images_patches')\n",
        "\n",
        "patch_size = (500, 500)  # Specify the desired patch size\n",
        "overlap = 250  # Specify the desired overlap size, 50% for this case\n",
        "\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(train_images_dir, image_file)\n",
        "    image = cv2.imread(image_path)   # Read image\n",
        "    patches = create_patches(image, patch_size, overlap)\n",
        "\n",
        "    for i, patch in enumerate(patches):\n",
        "        patch_name = f'{image_file[:-4]}_patch_{i+1}.tif'\n",
        "        cv2.imwrite(os.path.join(train_images_patches_dir, patch_name), patch)\n"
      ],
      "metadata": {
        "id": "8I4UitDClXX8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(train_images_patches_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XJ329I_ls6n",
        "outputId": "36304cc1-2933-4bf1-ae0f-d2b4833f8097"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50540"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "train_gt_patches_dir = os.path.join(absolute_path, 'train_targetpatches/gt_patches')\n",
        "\n",
        "# Construct the absolute path to the \"train/images\" directory for reading\n",
        "train_gt_dir = new_train_target\n",
        "\n",
        "# Retrieve a list of files in the \"train/images\" directory\n",
        "files = os.listdir(train_gt_dir)\n",
        "\n",
        "# Filter files based on criteria (e.g., file extension)\n",
        "gt_files = [file for file in sorted(files) if file.endswith('.tif')]\n",
        "\n",
        "patch_size = (500, 500)  # Specify the desired patch size\n",
        "overlap = 250  # Specify the desired overlap size, 50% for this case\n",
        "\n",
        "\n",
        "for image_file in gt_files:\n",
        "    image_path = os.path.join(train_gt_dir, image_file)\n",
        "    image = cv2.imread(image_path)   # Read image\n",
        "    patches = create_patches(image, patch_size, overlap)\n",
        "\n",
        "    for i, patch in enumerate(patches):\n",
        "        patch_name = f'{image_file[:-4]}_patch_{i+1}.tif'\n",
        "        cv2.imwrite(os.path.join(train_gt_patches_dir, patch_name), patch)"
      ],
      "metadata": {
        "id": "k4M4UNzMmiVA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(train_gt_patches_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DsgeeWQo8qQ",
        "outputId": "7e8d9d3b-e315-478e-fbf0-b31306e58a48"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50540"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Validation Patches"
      ],
      "metadata": {
        "id": "5v5kxjWF076G"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Construct the absolute path to the \"train/images\" directory for reading\n",
        "val_images_dir = new_val_input\n",
        "\n",
        "# Retrieve a list of files in the \"train/images\" directory\n",
        "files = os.listdir(val_images_dir)\n",
        "\n",
        "# Filter files based on criteria (e.g., file extension)\n",
        "image_files = [file for file in sorted(files) if file.endswith('.tif')]\n",
        "\n",
        "# Construct the relative path to the \"train_patches\" directory for writing\n",
        "val_images_patches_dir = os.path.join(absolute_path, 'val_patches/images_patches')\n",
        "val_gt_patches_dir = os.path.join(absolute_path, 'val_targetpatches/gt_patches')\n",
        "\n",
        "patch_size = (500, 500)  # Specify the desired patch size\n",
        "overlap = 250  # Specify the desired overlap size, 50% for this case\n",
        "\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(val_images_dir, image_file)\n",
        "    image = cv2.imread(image_path)   # Read image\n",
        "    patches = create_patches(image, patch_size, overlap)\n",
        "\n",
        "    for i, patch in enumerate(patches):\n",
        "        patch_name = f'{image_file[:-4]}_patch_{i+1}.tif'\n",
        "        cv2.imwrite(os.path.join(val_images_patches_dir, patch_name), patch)"
      ],
      "metadata": {
        "id": "Ugto0TUQ1NSK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(val_images_patches_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS8qw49j11WL",
        "outputId": "9c17b2d8-ebc1-4929-8d50-334ca4cba16a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14440"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "# Construct the absolute path to the \"train/images\" directory for reading\n",
        "val_gt_dir = new_val_target\n",
        "\n",
        "# Retrieve a list of files in the \"train/images\" directory\n",
        "files = os.listdir(val_gt_dir)\n",
        "\n",
        "# Filter files based on criteria (e.g., file extension)\n",
        "gt_files = [file for file in sorted(files) if file.endswith('.tif')]\n",
        "\n",
        "patch_size = (500, 500)  # Specify the desired patch size\n",
        "overlap = 250  # Specify the desired overlap size, 50% for this case\n",
        "\n",
        "\n",
        "for image_file in gt_files:\n",
        "    image_path = os.path.join(val_gt_dir, image_file)\n",
        "    image = cv2.imread(image_path)   # Read image\n",
        "    patches = create_patches(image, patch_size, overlap)\n",
        "\n",
        "    for i, patch in enumerate(patches):\n",
        "        patch_name = f'{image_file[:-4]}_patch_{i+1}.tif'\n",
        "        cv2.imwrite(os.path.join(val_gt_patches_dir, patch_name), patch)"
      ],
      "metadata": {
        "id": "FD-Q7uEf0gtq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(val_gt_patches_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nGQvYdZ1KJK",
        "outputId": "8c44a392-f1c9-4751-acf7-5e5eb66fcb22"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14440"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an image generator / data augmentation pipeline \n",
        "# augment data in train dataset only\n",
        "\n",
        "BATCH_SIZE = 5\n",
        "TARGET_SIZE = (512,512)\n",
        "seed = 23\n",
        "# patch_size = (500, 500)  # Specify the desired patch size\n",
        "# overlap = 250  # Specify the desired overlap size, 50% for this case\n",
        "\n",
        "train_patch_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   samplewise_std_normalization=False, \n",
        "                                   horizontal_flip = True, \n",
        "                                   vertical_flip = False, # 1st run : False, 2nd run: True\n",
        "                                   height_shift_range = 0.1, \n",
        "                                   width_shift_range = 0.1, \n",
        "                                   rotation_range = 3, # 1st run : 3, 2nd run:10\n",
        "                                   shear_range = 0.01, # 1st run : 0.01, 2nd run: 0.1\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   zoom_range = 0.05, #1st run 0.05, 2nd run: 0.1\n",
        "                                   zca_whitening = True,\n",
        "                                   zca_epsilon=1e-5, \n",
        "                                   )\n",
        "\n",
        "\n",
        "target_patch_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   samplewise_std_normalization=False, \n",
        "                                   horizontal_flip = True, \n",
        "                                   vertical_flip = False, # 1st run : False, 2nd run: True\n",
        "                                   height_shift_range = 0.1, \n",
        "                                   width_shift_range = 0.1, \n",
        "                                   rotation_range = 3, # 1st run : 3, 2nd run:10\n",
        "                                   shear_range = 0.01, # 1st run : 0.01, 2nd run: 0.1\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   zoom_range = 0.05, #1st run 0.05, 2nd run: 0.1\n",
        "                                   zca_whitening = True,\n",
        "                                   zca_epsilon=1e-5, \n",
        "                                   )\n",
        "\n",
        "val_patch_input_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_patch_target_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woFPd_81m_Gb",
        "outputId": "a724c643-7e16-41b1-cce5-699e2fe3cc01"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use data augmentation pipeline and start loading train data from folders\n",
        "TARGET_SIZE = (512,512)\n",
        "\n",
        "train_generator_input_patch = train_patch_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/train_patches/',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    seed = seed\n",
        "\n",
        ")\n",
        "\n",
        "train_generator_output_patch = target_patch_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/train_targetpatches/',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    seed = seed\n",
        ")\n",
        "\n",
        "train_patch_generator = zip(train_generator_input_patch, train_generator_output_patch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxgxbgr6nHid",
        "outputId": "8aad358e-23c2-41fc-dd99-935e1bae865d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50540 images belonging to 1 classes.\n",
            "Found 50540 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use data augmentation pipeline and start loading validation data from folders\n",
        "\n",
        "val_generator_input_patch = val_patch_input_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/val_patches/',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    seed = seed\n",
        "\n",
        ")\n",
        "\n",
        "val_generator_output_patch = val_patch_target_datagen.flow_from_directory(\n",
        "    '/content/aerialimage/val_targetpatches/',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    seed = seed\n",
        ")\n",
        "\n",
        "val_patch_generator = zip(val_generator_input_patch, val_generator_output_patch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdFzS8BenKTC",
        "outputId": "5eee55d3-ccf9-4f2a-bd6a-2f471ac4304b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14440 images belonging to 1 classes.\n",
            "Found 14440 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/model_checkpoint\n",
        "!mkdir /content/model_log"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:31.580221Z",
          "iopub.execute_input": "2023-05-24T11:53:31.582102Z",
          "iopub.status.idle": "2023-05-24T11:53:33.866992Z",
          "shell.execute_reply.started": "2023-05-24T11:53:31.582058Z",
          "shell.execute_reply": "2023-05-24T11:53:33.865484Z"
        },
        "trusted": true,
        "id": "uGWDSgl0ntSo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st run\n",
        "model_file = '/content/model_checkpoint/model_checkpoint_patch.h5'\n",
        "log_file =  '/content/model_log/model_log_patch.csv'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:41.069739Z",
          "iopub.execute_input": "2023-05-24T11:53:41.070223Z",
          "iopub.status.idle": "2023-05-24T11:53:41.077229Z",
          "shell.execute_reply.started": "2023-05-24T11:53:41.070185Z",
          "shell.execute_reply": "2023-05-24T11:53:41.076061Z"
        },
        "trusted": true,
        "id": "yP3m7cqmntSo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unet"
      ],
      "metadata": {
        "id": "t1t0pigyntSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = (512, 512, 3)\n",
        "model = build_unet(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:45.776476Z",
          "iopub.execute_input": "2023-05-24T11:53:45.777484Z",
          "iopub.status.idle": "2023-05-24T11:53:46.494489Z",
          "shell.execute_reply.started": "2023-05-24T11:53:45.777446Z",
          "shell.execute_reply": "2023-05-24T11:53:46.481179Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op5RdeNpntSq",
        "outputId": "79a233a0-e93a-415d-b701-ec82cc43145f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_276 (Conv2D)            (None, 512, 512, 64  1792        ['input_15[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_300 (Batch  (None, 512, 512, 64  256        ['conv2d_276[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_267 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_300[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_277 (Conv2D)            (None, 512, 512, 64  36928       ['activation_267[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_301 (Batch  (None, 512, 512, 64  256        ['conv2d_277[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_268 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_301[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooling2D  (None, 256, 256, 64  0          ['activation_268[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_278 (Conv2D)            (None, 256, 256, 12  73856       ['max_pooling2d_33[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_302 (Batch  (None, 256, 256, 12  512        ['conv2d_278[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_269 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_302[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_279 (Conv2D)            (None, 256, 256, 12  147584      ['activation_269[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_303 (Batch  (None, 256, 256, 12  512        ['conv2d_279[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_270 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_303[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_34 (MaxPooling2D  (None, 128, 128, 12  0          ['activation_270[0][0]']         \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_280 (Conv2D)            (None, 128, 128, 25  295168      ['max_pooling2d_34[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_304 (Batch  (None, 128, 128, 25  1024       ['conv2d_280[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_271 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_304[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_281 (Conv2D)            (None, 128, 128, 25  590080      ['activation_271[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_305 (Batch  (None, 128, 128, 25  1024       ['conv2d_281[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_272 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_305[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_35 (MaxPooling2D  (None, 64, 64, 256)  0          ['activation_272[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_282 (Conv2D)            (None, 64, 64, 512)  1180160     ['max_pooling2d_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_306 (Batch  (None, 64, 64, 512)  2048       ['conv2d_282[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_273 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_306[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_283 (Conv2D)            (None, 64, 64, 512)  2359808     ['activation_273[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_307 (Batch  (None, 64, 64, 512)  2048       ['conv2d_283[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_274 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_307[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_36 (MaxPooling2D  (None, 32, 32, 512)  0          ['activation_274[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_284 (Conv2D)            (None, 32, 32, 1024  4719616     ['max_pooling2d_36[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_308 (Batch  (None, 32, 32, 1024  4096       ['conv2d_284[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_275 (Activation)    (None, 32, 32, 1024  0           ['batch_normalization_308[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_285 (Conv2D)            (None, 32, 32, 1024  9438208     ['activation_275[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_309 (Batch  (None, 32, 32, 1024  4096       ['conv2d_285[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_276 (Activation)    (None, 32, 32, 1024  0           ['batch_normalization_309[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_92 (Conv2DTra  (None, 64, 64, 512)  2097664    ['activation_276[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_95 (Concatenate)   (None, 64, 64, 1024  0           ['conv2d_transpose_92[0][0]',    \n",
            "                                )                                 'activation_274[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_286 (Conv2D)            (None, 64, 64, 512)  4719104     ['concatenate_95[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_310 (Batch  (None, 64, 64, 512)  2048       ['conv2d_286[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_277 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_310[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_287 (Conv2D)            (None, 64, 64, 512)  2359808     ['activation_277[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_311 (Batch  (None, 64, 64, 512)  2048       ['conv2d_287[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_278 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_311[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_93 (Conv2DTra  (None, 128, 128, 25  524544     ['activation_278[0][0]']         \n",
            " nspose)                        6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_96 (Concatenate)   (None, 128, 128, 51  0           ['conv2d_transpose_93[0][0]',    \n",
            "                                2)                                'activation_272[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_288 (Conv2D)            (None, 128, 128, 25  1179904     ['concatenate_96[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_312 (Batch  (None, 128, 128, 25  1024       ['conv2d_288[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_279 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_312[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_289 (Conv2D)            (None, 128, 128, 25  590080      ['activation_279[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_313 (Batch  (None, 128, 128, 25  1024       ['conv2d_289[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_280 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_313[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_94 (Conv2DTra  (None, 256, 256, 12  131200     ['activation_280[0][0]']         \n",
            " nspose)                        8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_97 (Concatenate)   (None, 256, 256, 25  0           ['conv2d_transpose_94[0][0]',    \n",
            "                                6)                                'activation_270[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_290 (Conv2D)            (None, 256, 256, 12  295040      ['concatenate_97[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_314 (Batch  (None, 256, 256, 12  512        ['conv2d_290[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_281 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_314[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_291 (Conv2D)            (None, 256, 256, 12  147584      ['activation_281[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_315 (Batch  (None, 256, 256, 12  512        ['conv2d_291[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_282 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_315[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_95 (Conv2DTra  (None, 512, 512, 64  32832      ['activation_282[0][0]']         \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_98 (Concatenate)   (None, 512, 512, 12  0           ['conv2d_transpose_95[0][0]',    \n",
            "                                8)                                'activation_268[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_292 (Conv2D)            (None, 512, 512, 64  73792       ['concatenate_98[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_316 (Batch  (None, 512, 512, 64  256        ['conv2d_292[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_283 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_316[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_293 (Conv2D)            (None, 512, 512, 64  36928       ['activation_283[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_317 (Batch  (None, 512, 512, 64  256        ['conv2d_293[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_284 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_317[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_294 (Conv2D)            (None, 512, 512, 1)  65          ['activation_284[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,055,297\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## u2net"
      ],
      "metadata": {
        "id": "3TxK2hAZpWo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Add\n",
        "\n",
        "def conv_block(inputs, out_ch, rate=1):\n",
        "    x = Conv2D(out_ch, 3, padding=\"same\", dilation_rate=1)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def RSU_L(inputs, out_ch, int_ch, num_layers, rate=2):\n",
        "    \"\"\" Initial Conv \"\"\"\n",
        "    x = conv_block(inputs, out_ch)\n",
        "    init_feats = x\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    skip = []\n",
        "    x = conv_block(x, int_ch)\n",
        "    skip.append(x)\n",
        "\n",
        "    for i in range(num_layers-2):\n",
        "        x = MaxPool2D((2, 2))(x)\n",
        "        x = conv_block(x, int_ch)\n",
        "        skip.append(x)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    x = conv_block(x, int_ch, rate=rate)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    skip.reverse()\n",
        "\n",
        "    x = Concatenate()([x, skip[0]])\n",
        "    x = conv_block(x, int_ch)\n",
        "\n",
        "    for i in range(num_layers-3):\n",
        "        x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n",
        "        x = Concatenate()([x, skip[i+1]])\n",
        "        x = conv_block(x, int_ch)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n",
        "    x = Concatenate()([x, skip[-1]])\n",
        "    x = conv_block(x, out_ch)\n",
        "\n",
        "    \"\"\" Add \"\"\"\n",
        "    x = Add()([x, init_feats])\n",
        "    return x\n",
        "\n",
        "def RSU_4F(inputs, out_ch, int_ch):\n",
        "    \"\"\" Initial Conv \"\"\"\n",
        "    x0 = conv_block(inputs, out_ch, rate=1)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    x1 = conv_block(x0, int_ch, rate=1)\n",
        "    x2 = conv_block(x1, int_ch, rate=2)\n",
        "    x3 = conv_block(x2, int_ch, rate=4)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    x4 = conv_block(x3, int_ch, rate=8)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    x = Concatenate()([x4, x3])\n",
        "    x = conv_block(x, int_ch, rate=4)\n",
        "\n",
        "    x = Concatenate()([x, x2])\n",
        "    x = conv_block(x, int_ch, rate=2)\n",
        "\n",
        "    x = Concatenate()([x, x1])\n",
        "    x = conv_block(x, out_ch, rate=1)\n",
        "\n",
        "    \"\"\" Addition \"\"\"\n",
        "    x = Add()([x, x0])\n",
        "    return x\n",
        "\n",
        "def u2net(input_shape, out_ch, int_ch, num_classes=1):\n",
        "    \"\"\" Input Layer \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    s0 = inputs\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = RSU_L(s0, out_ch[0], int_ch[0], 7)\n",
        "    p1 = MaxPool2D((2, 2))(s1)\n",
        "\n",
        "    s2 = RSU_L(p1, out_ch[1], int_ch[1], 6)\n",
        "    p2 = MaxPool2D((2, 2))(s2)\n",
        "\n",
        "    s3 = RSU_L(p2, out_ch[2], int_ch[2], 5)\n",
        "    p3 = MaxPool2D((2, 2))(s3)\n",
        "\n",
        "    s4 = RSU_L(p3, out_ch[3], int_ch[3], 4)\n",
        "    p4 = MaxPool2D((2, 2))(s4)\n",
        "\n",
        "    s5 = RSU_4F(p4, out_ch[4], int_ch[4])\n",
        "    p5 = MaxPool2D((2, 2))(s5)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = RSU_4F(p5, out_ch[5], int_ch[5])\n",
        "    b2 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(b1)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = Concatenate()([b2, s5])\n",
        "    d1 = RSU_4F(d1, out_ch[6], int_ch[6])\n",
        "    u1 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d1)\n",
        "\n",
        "    d2 = Concatenate()([u1, s4])\n",
        "    d2 = RSU_L(d2, out_ch[7], int_ch[7], 4)\n",
        "    u2 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d2)\n",
        "\n",
        "    d3 = Concatenate()([u2, s3])\n",
        "    d3 = RSU_L(d3, out_ch[8], int_ch[8], 5)\n",
        "    u3 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d3)\n",
        "\n",
        "    d4 = Concatenate()([u3, s2])\n",
        "    d4 = RSU_L(d4, out_ch[9], int_ch[9], 6)\n",
        "    u4 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d4)\n",
        "\n",
        "    d5 = Concatenate()([u4, s1])\n",
        "    d5 = RSU_L(d5, out_ch[10], int_ch[10], 7)\n",
        "\n",
        "    \"\"\" Side Outputs \"\"\"\n",
        "    y1 = Conv2D(num_classes, 3, padding=\"same\")(d5)\n",
        "\n",
        "    y2 = Conv2D(num_classes, 3, padding=\"same\")(d4)\n",
        "    y2 = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(y2)\n",
        "\n",
        "    y3 = Conv2D(num_classes, 3, padding=\"same\")(d3)\n",
        "    y3 = UpSampling2D(size=(4, 4), interpolation=\"bilinear\")(y3)\n",
        "\n",
        "    y4 = Conv2D(num_classes, 3, padding=\"same\")(d2)\n",
        "    y4 = UpSampling2D(size=(8, 8), interpolation=\"bilinear\")(y4)\n",
        "\n",
        "    y5 = Conv2D(num_classes, 3, padding=\"same\")(d1)\n",
        "    y5 = UpSampling2D(size=(16, 16), interpolation=\"bilinear\")(y5)\n",
        "\n",
        "    y6 = Conv2D(num_classes, 3, padding=\"same\")(b1)\n",
        "    y6 = UpSampling2D(size=(32, 32), interpolation=\"bilinear\")(y6)\n",
        "\n",
        "    y0 = Concatenate()([y1, y2, y3, y4, y5, y6])\n",
        "    y0 = Conv2D(num_classes, 3, padding=\"same\")(y0)\n",
        "\n",
        "    y0 = Activation(\"sigmoid\")(y0)\n",
        "    y1 = Activation(\"sigmoid\")(y1)\n",
        "    y2 = Activation(\"sigmoid\")(y2)\n",
        "    y3 = Activation(\"sigmoid\")(y3)\n",
        "    y4 = Activation(\"sigmoid\")(y4)\n",
        "    y5 = Activation(\"sigmoid\")(y5)\n",
        "    y6 = Activation(\"sigmoid\")(y6)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs, outputs=[y0, y1, y2, y3, y4, y5, y6])\n",
        "    return model\n",
        "\n",
        "def build_u2net(input_shape, num_classes=1):\n",
        "    out_ch = [64, 128, 256, 512, 512, 512, 512, 256, 128, 64, 64]\n",
        "    int_ch = [32, 32, 64, 128, 256, 256, 256, 128, 64, 32, 16]\n",
        "    model = u2net(input_shape, out_ch, int_ch, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "def build_u2net_lite(input_shape, num_classes=1):\n",
        "    out_ch = [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]\n",
        "    int_ch = [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
        "    model = u2net(input_shape, out_ch, int_ch, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_u2net_lite((512, 512, 3))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNlabyMdO-tC",
        "outputId": "df4442e1-2364-442e-aff6-5ebef49eee47"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 512, 512, 64  1792        ['input_11[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 512, 512, 64  256        ['conv2d_130[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_164[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 512, 512, 16  9232        ['activation_124[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 512, 512, 16  64         ['conv2d_131[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_165[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 16  0           ['activation_125[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 256, 256, 16  2320        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 256, 256, 16  64         ['conv2d_132[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 256, 256, 16  0           ['batch_normalization_166[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16  0          ['activation_126[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 128, 128, 16  2320        ['max_pooling2d_1[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 128, 128, 16  64         ['conv2d_133[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_167[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 16)  0           ['activation_127[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 64, 64, 16)   2320        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 64, 64, 16)  64          ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 16)  0           ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 32, 32, 16)  64          ['conv2d_135[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)  0           ['activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 16, 16, 16)  64          ['conv2d_136[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 16, 16, 16)  64          ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 16, 16, 32)   0           ['activation_131[0][0]',         \n",
            "                                                                  'activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_32[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 16, 16, 16)  64          ['conv2d_138[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 16)   0           ['activation_132[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 32, 32, 16)  64          ['conv2d_139[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 16)  0           ['activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_1[0][0]',        \n",
            "                                                                  'activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 64, 64, 16)   4624        ['concatenate_34[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 64, 64, 16)  64          ['conv2d_140[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 16  0          ['activation_134[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 128, 128, 32  0           ['up_sampling2d_2[0][0]',        \n",
            "                                )                                 'activation_127[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_35[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 128, 128, 16  64         ['conv2d_141[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_175[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 16  0          ['activation_135[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 256, 256, 32  0           ['up_sampling2d_3[0][0]',        \n",
            "                                )                                 'activation_126[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 256, 256, 16  4624        ['concatenate_36[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 256, 256, 16  64         ['conv2d_142[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 256, 256, 16  0           ['batch_normalization_176[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 16  0          ['activation_136[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 512, 512, 32  0           ['up_sampling2d_4[0][0]',        \n",
            "                                )                                 'activation_125[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 512, 512, 64  18496       ['concatenate_37[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 512, 512, 64  256        ['conv2d_143[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_177[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_216 (Add)                  (None, 512, 512, 64  0           ['activation_137[0][0]',         \n",
            "                                )                                 'activation_124[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 256, 256, 64  0          ['add_216[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 256, 256, 64  36928       ['max_pooling2d_5[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 256, 256, 64  256        ['conv2d_144[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_178[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 256, 256, 16  9232        ['activation_138[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 256, 256, 16  64         ['conv2d_145[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 256, 256, 16  0           ['batch_normalization_179[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 128, 128, 16  0          ['activation_139[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 128, 128, 16  2320        ['max_pooling2d_6[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 128, 128, 16  64         ['conv2d_146[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_180[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 16)  0           ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 64, 64, 16)   2320        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 64, 64, 16)  64          ['conv2d_147[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 16)  0           ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 32, 32, 16)  64          ['conv2d_148[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 16)  0           ['activation_142[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 16, 16, 16)  64          ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 16, 16, 16)  64          ['conv2d_150[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_184[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 16, 16, 32)   0           ['activation_144[0][0]',         \n",
            "                                                                  'activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_38[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 16, 16, 16)  64          ['conv2d_151[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_185[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 16)  0           ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_5[0][0]',        \n",
            "                                                                  'activation_142[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_39[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 32, 32, 16)  64          ['conv2d_152[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 16)  0           ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_6[0][0]',        \n",
            "                                                                  'activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 64, 64, 16)   4624        ['concatenate_40[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 64, 64, 16)  64          ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_187[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 16  0          ['activation_147[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, 128, 128, 32  0           ['up_sampling2d_7[0][0]',        \n",
            "                                )                                 'activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_41[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_188 (Batch  (None, 128, 128, 16  64         ['conv2d_154[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_188[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 16  0          ['activation_148[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenate)   (None, 256, 256, 32  0           ['up_sampling2d_8[0][0]',        \n",
            "                                )                                 'activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 256, 256, 64  18496       ['concatenate_42[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_189 (Batch  (None, 256, 256, 64  256        ['conv2d_155[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_189[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_217 (Add)                  (None, 256, 256, 64  0           ['activation_149[0][0]',         \n",
            "                                )                                 'activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 128, 128, 64  0          ['add_217[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 128, 128, 64  36928       ['max_pooling2d_10[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_190 (Batch  (None, 128, 128, 64  256        ['conv2d_156[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_190[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 128, 128, 16  9232        ['activation_150[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_191 (Batch  (None, 128, 128, 16  64         ['conv2d_157[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_191[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 64, 64, 16)  0           ['activation_151[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 64, 64, 16)   2320        ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_192 (Batch  (None, 64, 64, 16)  64          ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_192[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 32, 32, 16)  0           ['activation_152[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_193 (Batch  (None, 32, 32, 16)  64          ['conv2d_159[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_193[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 16, 16, 16)  0           ['activation_153[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_194 (Batch  (None, 16, 16, 16)  64          ['conv2d_160[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_194[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_154[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_195 (Batch  (None, 16, 16, 16)  64          ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_195[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 16, 16, 32)   0           ['activation_155[0][0]',         \n",
            "                                                                  'activation_154[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_43[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_196 (Batch  (None, 16, 16, 16)  64          ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_196[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 16)  0           ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_9[0][0]',        \n",
            "                                                                  'activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_44[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_197 (Batch  (None, 32, 32, 16)  64          ['conv2d_163[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_197[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_10 (UpSampling2D  (None, 64, 64, 16)  0           ['activation_157[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_10[0][0]',       \n",
            "                                                                  'activation_152[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 64, 64, 16)   4624        ['concatenate_45[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_198 (Batch  (None, 64, 64, 16)  64          ['conv2d_164[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_198[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_11 (UpSampling2D  (None, 128, 128, 16  0          ['activation_158[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 128, 128, 32  0           ['up_sampling2d_11[0][0]',       \n",
            "                                )                                 'activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 128, 128, 64  18496       ['concatenate_46[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_199 (Batch  (None, 128, 128, 64  256        ['conv2d_165[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_199[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_218 (Add)                  (None, 128, 128, 64  0           ['activation_159[0][0]',         \n",
            "                                )                                 'activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 64, 64, 64)  0           ['add_218[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 64, 64, 64)   36928       ['max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_200 (Batch  (None, 64, 64, 64)  256         ['conv2d_166[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 64, 64, 64)   0           ['batch_normalization_200[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 64, 64, 16)   9232        ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_201 (Batch  (None, 64, 64, 16)  64          ['conv2d_167[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_201[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, 32, 32, 16)  0           ['activation_161[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_202 (Batch  (None, 32, 32, 16)  64          ['conv2d_168[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_202[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_16 (MaxPooling2D  (None, 16, 16, 16)  0           ['activation_162[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_203 (Batch  (None, 16, 16, 16)  64          ['conv2d_169[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_203[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_204 (Batch  (None, 16, 16, 16)  64          ['conv2d_170[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_204[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 16, 16, 32)   0           ['activation_164[0][0]',         \n",
            "                                                                  'activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_47[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_205 (Batch  (None, 16, 16, 16)  64          ['conv2d_171[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_205[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_12 (UpSampling2D  (None, 32, 32, 16)  0           ['activation_165[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_12[0][0]',       \n",
            "                                                                  'activation_162[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_48[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_206 (Batch  (None, 32, 32, 16)  64          ['conv2d_172[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_206[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_13 (UpSampling2D  (None, 64, 64, 16)  0           ['activation_166[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_13[0][0]',       \n",
            "                                                                  'activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 64, 64, 64)   18496       ['concatenate_49[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_207 (Batch  (None, 64, 64, 64)  256         ['conv2d_173[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 64, 64, 64)   0           ['batch_normalization_207[0][0]']\n",
            "                                                                                                  \n",
            " add_219 (Add)                  (None, 64, 64, 64)   0           ['activation_167[0][0]',         \n",
            "                                                                  'activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_17 (MaxPooling2D  (None, 32, 32, 64)  0           ['add_219[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 32, 32, 64)   36928       ['max_pooling2d_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_208 (Batch  (None, 32, 32, 64)  256         ['conv2d_174[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_208[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 32, 32, 16)   9232        ['activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_209 (Batch  (None, 32, 32, 16)  64          ['conv2d_175[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_209[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_169[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_210 (Batch  (None, 32, 32, 16)  64          ['conv2d_176[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_210[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_170[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_211 (Batch  (None, 32, 32, 16)  64          ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_211[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_212 (Batch  (None, 32, 32, 16)  64          ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_212[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenate)   (None, 32, 32, 32)   0           ['activation_172[0][0]',         \n",
            "                                                                  'activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_50[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_213 (Batch  (None, 32, 32, 16)  64          ['conv2d_179[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_213[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenate)   (None, 32, 32, 32)   0           ['activation_173[0][0]',         \n",
            "                                                                  'activation_170[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_51[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_214 (Batch  (None, 32, 32, 16)  64          ['conv2d_180[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_214[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenate)   (None, 32, 32, 32)   0           ['activation_174[0][0]',         \n",
            "                                                                  'activation_169[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 32, 32, 64)   18496       ['concatenate_52[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_215 (Batch  (None, 32, 32, 64)  256         ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_215[0][0]']\n",
            "                                                                                                  \n",
            " add_220 (Add)                  (None, 32, 32, 64)   0           ['activation_175[0][0]',         \n",
            "                                                                  'activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooling2D  (None, 16, 16, 64)  0           ['add_220[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 16, 16, 64)   36928       ['max_pooling2d_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_216 (Batch  (None, 16, 16, 64)  256         ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_216[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 16, 16, 16)   9232        ['activation_176[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_217 (Batch  (None, 16, 16, 16)  64          ['conv2d_183[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_217[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_218 (Batch  (None, 16, 16, 16)  64          ['conv2d_184[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_218[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_219 (Batch  (None, 16, 16, 16)  64          ['conv2d_185[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_219[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_179[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_220 (Batch  (None, 16, 16, 16)  64          ['conv2d_186[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_220[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenate)   (None, 16, 16, 32)   0           ['activation_180[0][0]',         \n",
            "                                                                  'activation_179[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_53[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_221 (Batch  (None, 16, 16, 16)  64          ['conv2d_187[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_221[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenate)   (None, 16, 16, 32)   0           ['activation_181[0][0]',         \n",
            "                                                                  'activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_188 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_54[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_222 (Batch  (None, 16, 16, 16)  64          ['conv2d_188[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_222[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenate)   (None, 16, 16, 32)   0           ['activation_182[0][0]',         \n",
            "                                                                  'activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_189 (Conv2D)            (None, 16, 16, 64)   18496       ['concatenate_55[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_223 (Batch  (None, 16, 16, 64)  256         ['conv2d_189[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_223[0][0]']\n",
            "                                                                                                  \n",
            " add_221 (Add)                  (None, 16, 16, 64)   0           ['activation_183[0][0]',         \n",
            "                                                                  'activation_176[0][0]']         \n",
            "                                                                                                  \n",
            " up_sampling2d_14 (UpSampling2D  (None, 32, 32, 64)  0           ['add_221[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenate)   (None, 32, 32, 128)  0           ['up_sampling2d_14[0][0]',       \n",
            "                                                                  'add_220[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_190 (Conv2D)            (None, 32, 32, 64)   73792       ['concatenate_56[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_224 (Batch  (None, 32, 32, 64)  256         ['conv2d_190[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_224[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)            (None, 32, 32, 16)   9232        ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_225 (Batch  (None, 32, 32, 16)  64          ['conv2d_191[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_225[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_185[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_226 (Batch  (None, 32, 32, 16)  64          ['conv2d_192[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_226[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_227 (Batch  (None, 32, 32, 16)  64          ['conv2d_193[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_227[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_187[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_228 (Batch  (None, 32, 32, 16)  64          ['conv2d_194[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_188 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_228[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenate)   (None, 32, 32, 32)   0           ['activation_188[0][0]',         \n",
            "                                                                  'activation_187[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_195 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_57[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_229 (Batch  (None, 32, 32, 16)  64          ['conv2d_195[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_189 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_229[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_58 (Concatenate)   (None, 32, 32, 32)   0           ['activation_189[0][0]',         \n",
            "                                                                  'activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_196 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_58[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_230 (Batch  (None, 32, 32, 16)  64          ['conv2d_196[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_190 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_230[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_59 (Concatenate)   (None, 32, 32, 32)   0           ['activation_190[0][0]',         \n",
            "                                                                  'activation_185[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_197 (Conv2D)            (None, 32, 32, 64)   18496       ['concatenate_59[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_231 (Batch  (None, 32, 32, 64)  256         ['conv2d_197[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_191 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_231[0][0]']\n",
            "                                                                                                  \n",
            " add_222 (Add)                  (None, 32, 32, 64)   0           ['activation_191[0][0]',         \n",
            "                                                                  'activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " up_sampling2d_15 (UpSampling2D  (None, 64, 64, 64)  0           ['add_222[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenate)   (None, 64, 64, 128)  0           ['up_sampling2d_15[0][0]',       \n",
            "                                                                  'add_219[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)            (None, 64, 64, 64)   73792       ['concatenate_60[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_232 (Batch  (None, 64, 64, 64)  256         ['conv2d_198[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_192 (Activation)    (None, 64, 64, 64)   0           ['batch_normalization_232[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)            (None, 64, 64, 16)   9232        ['activation_192[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_233 (Batch  (None, 64, 64, 16)  64          ['conv2d_199[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_193 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_233[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooling2D  (None, 32, 32, 16)  0           ['activation_193[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_19[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_234 (Batch  (None, 32, 32, 16)  64          ['conv2d_200[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_194 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_234[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooling2D  (None, 16, 16, 16)  0           ['activation_194[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_235 (Batch  (None, 16, 16, 16)  64          ['conv2d_201[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_195 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_235[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_195[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_236 (Batch  (None, 16, 16, 16)  64          ['conv2d_202[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_196 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_236[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenate)   (None, 16, 16, 32)   0           ['activation_196[0][0]',         \n",
            "                                                                  'activation_195[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_61[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_237 (Batch  (None, 16, 16, 16)  64          ['conv2d_203[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_197 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_237[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_16 (UpSampling2D  (None, 32, 32, 16)  0           ['activation_197[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_62 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_16[0][0]',       \n",
            "                                                                  'activation_194[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_62[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_238 (Batch  (None, 32, 32, 16)  64          ['conv2d_204[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_198 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_238[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_17 (UpSampling2D  (None, 64, 64, 16)  0           ['activation_198[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_63 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_17[0][0]',       \n",
            "                                                                  'activation_193[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)            (None, 64, 64, 64)   18496       ['concatenate_63[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_239 (Batch  (None, 64, 64, 64)  256         ['conv2d_205[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_199 (Activation)    (None, 64, 64, 64)   0           ['batch_normalization_239[0][0]']\n",
            "                                                                                                  \n",
            " add_223 (Add)                  (None, 64, 64, 64)   0           ['activation_199[0][0]',         \n",
            "                                                                  'activation_192[0][0]']         \n",
            "                                                                                                  \n",
            " up_sampling2d_18 (UpSampling2D  (None, 128, 128, 64  0          ['add_223[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_64 (Concatenate)   (None, 128, 128, 12  0           ['up_sampling2d_18[0][0]',       \n",
            "                                8)                                'add_218[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)            (None, 128, 128, 64  73792       ['concatenate_64[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_240 (Batch  (None, 128, 128, 64  256        ['conv2d_206[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_200 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_240[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)            (None, 128, 128, 16  9232        ['activation_200[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_241 (Batch  (None, 128, 128, 16  64         ['conv2d_207[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_201 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_241[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 16)  0           ['activation_201[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)            (None, 64, 64, 16)   2320        ['max_pooling2d_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_242 (Batch  (None, 64, 64, 16)  64          ['conv2d_208[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_202 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_242[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 16)  0           ['activation_202[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_243 (Batch  (None, 32, 32, 16)  64          ['conv2d_209[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_203 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_243[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 16)  0           ['activation_203[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_244 (Batch  (None, 16, 16, 16)  64          ['conv2d_210[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_204 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_244[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_204[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_245 (Batch  (None, 16, 16, 16)  64          ['conv2d_211[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_205 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_245[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_65 (Concatenate)   (None, 16, 16, 32)   0           ['activation_205[0][0]',         \n",
            "                                                                  'activation_204[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_65[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_246 (Batch  (None, 16, 16, 16)  64          ['conv2d_212[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_206 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_246[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_19 (UpSampling2D  (None, 32, 32, 16)  0           ['activation_206[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_66 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_19[0][0]',       \n",
            "                                                                  'activation_203[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_66[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_247 (Batch  (None, 32, 32, 16)  64          ['conv2d_213[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_207 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_247[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_20 (UpSampling2D  (None, 64, 64, 16)  0           ['activation_207[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_67 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_20[0][0]',       \n",
            "                                                                  'activation_202[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)            (None, 64, 64, 16)   4624        ['concatenate_67[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_248 (Batch  (None, 64, 64, 16)  64          ['conv2d_214[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_208 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_248[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_21 (UpSampling2D  (None, 128, 128, 16  0          ['activation_208[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_68 (Concatenate)   (None, 128, 128, 32  0           ['up_sampling2d_21[0][0]',       \n",
            "                                )                                 'activation_201[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)            (None, 128, 128, 64  18496       ['concatenate_68[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_249 (Batch  (None, 128, 128, 64  256        ['conv2d_215[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_209 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_249[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_224 (Add)                  (None, 128, 128, 64  0           ['activation_209[0][0]',         \n",
            "                                )                                 'activation_200[0][0]']         \n",
            "                                                                                                  \n",
            " up_sampling2d_22 (UpSampling2D  (None, 256, 256, 64  0          ['add_224[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_69 (Concatenate)   (None, 256, 256, 12  0           ['up_sampling2d_22[0][0]',       \n",
            "                                8)                                'add_217[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_69[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_250 (Batch  (None, 256, 256, 64  256        ['conv2d_216[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_210 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_250[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)            (None, 256, 256, 16  9232        ['activation_210[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_251 (Batch  (None, 256, 256, 16  64         ['conv2d_217[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_211 (Activation)    (None, 256, 256, 16  0           ['batch_normalization_251[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_24 (MaxPooling2D  (None, 128, 128, 16  0          ['activation_211[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)            (None, 128, 128, 16  2320        ['max_pooling2d_24[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_252 (Batch  (None, 128, 128, 16  64         ['conv2d_218[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_212 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_252[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_25 (MaxPooling2D  (None, 64, 64, 16)  0           ['activation_212[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)            (None, 64, 64, 16)   2320        ['max_pooling2d_25[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_253 (Batch  (None, 64, 64, 16)  64          ['conv2d_219[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_213 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_253[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_26 (MaxPooling2D  (None, 32, 32, 16)  0           ['activation_213[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_26[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_254 (Batch  (None, 32, 32, 16)  64          ['conv2d_220[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_214 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_254[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_27 (MaxPooling2D  (None, 16, 16, 16)  0           ['activation_214[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_255 (Batch  (None, 16, 16, 16)  64          ['conv2d_221[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_215 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_255[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_215[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_256 (Batch  (None, 16, 16, 16)  64          ['conv2d_222[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_216 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_256[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_70 (Concatenate)   (None, 16, 16, 32)   0           ['activation_216[0][0]',         \n",
            "                                                                  'activation_215[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_70[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_257 (Batch  (None, 16, 16, 16)  64          ['conv2d_223[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_217 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_257[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_23 (UpSampling2D  (None, 32, 32, 16)  0           ['activation_217[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_71 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_23[0][0]',       \n",
            "                                                                  'activation_214[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_71[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_258 (Batch  (None, 32, 32, 16)  64          ['conv2d_224[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_218 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_258[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_24 (UpSampling2D  (None, 64, 64, 16)  0           ['activation_218[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_72 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_24[0][0]',       \n",
            "                                                                  'activation_213[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)            (None, 64, 64, 16)   4624        ['concatenate_72[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_259 (Batch  (None, 64, 64, 16)  64          ['conv2d_225[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_219 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_259[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_25 (UpSampling2D  (None, 128, 128, 16  0          ['activation_219[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_73 (Concatenate)   (None, 128, 128, 32  0           ['up_sampling2d_25[0][0]',       \n",
            "                                )                                 'activation_212[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_73[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_260 (Batch  (None, 128, 128, 16  64         ['conv2d_226[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_220 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_260[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_26 (UpSampling2D  (None, 256, 256, 16  0          ['activation_220[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_74 (Concatenate)   (None, 256, 256, 32  0           ['up_sampling2d_26[0][0]',       \n",
            "                                )                                 'activation_211[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)            (None, 256, 256, 64  18496       ['concatenate_74[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_261 (Batch  (None, 256, 256, 64  256        ['conv2d_227[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_221 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_261[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_225 (Add)                  (None, 256, 256, 64  0           ['activation_221[0][0]',         \n",
            "                                )                                 'activation_210[0][0]']         \n",
            "                                                                                                  \n",
            " up_sampling2d_27 (UpSampling2D  (None, 512, 512, 64  0          ['add_225[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_75 (Concatenate)   (None, 512, 512, 12  0           ['up_sampling2d_27[0][0]',       \n",
            "                                8)                                'add_216[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)            (None, 512, 512, 64  73792       ['concatenate_75[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_262 (Batch  (None, 512, 512, 64  256        ['conv2d_228[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_222 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_262[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)            (None, 512, 512, 16  9232        ['activation_222[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_263 (Batch  (None, 512, 512, 16  64         ['conv2d_229[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_223 (Activation)    (None, 512, 512, 16  0           ['batch_normalization_263[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_28 (MaxPooling2D  (None, 256, 256, 16  0          ['activation_223[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)            (None, 256, 256, 16  2320        ['max_pooling2d_28[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_264 (Batch  (None, 256, 256, 16  64         ['conv2d_230[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_224 (Activation)    (None, 256, 256, 16  0           ['batch_normalization_264[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_29 (MaxPooling2D  (None, 128, 128, 16  0          ['activation_224[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)            (None, 128, 128, 16  2320        ['max_pooling2d_29[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_265 (Batch  (None, 128, 128, 16  64         ['conv2d_231[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_225 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_265[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_30 (MaxPooling2D  (None, 64, 64, 16)  0           ['activation_225[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)            (None, 64, 64, 16)   2320        ['max_pooling2d_30[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_266 (Batch  (None, 64, 64, 16)  64          ['conv2d_232[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_226 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_266[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_31 (MaxPooling2D  (None, 32, 32, 16)  0           ['activation_226[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)            (None, 32, 32, 16)   2320        ['max_pooling2d_31[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_267 (Batch  (None, 32, 32, 16)  64          ['conv2d_233[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_227 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_267[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_32 (MaxPooling2D  (None, 16, 16, 16)  0           ['activation_227[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)            (None, 16, 16, 16)   2320        ['max_pooling2d_32[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_268 (Batch  (None, 16, 16, 16)  64          ['conv2d_234[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_228 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_268[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)            (None, 16, 16, 16)   2320        ['activation_228[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_269 (Batch  (None, 16, 16, 16)  64          ['conv2d_235[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_229 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_269[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_76 (Concatenate)   (None, 16, 16, 32)   0           ['activation_229[0][0]',         \n",
            "                                                                  'activation_228[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)            (None, 16, 16, 16)   4624        ['concatenate_76[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_270 (Batch  (None, 16, 16, 16)  64          ['conv2d_236[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_230 (Activation)    (None, 16, 16, 16)   0           ['batch_normalization_270[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_28 (UpSampling2D  (None, 32, 32, 16)  0           ['activation_230[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_77 (Concatenate)   (None, 32, 32, 32)   0           ['up_sampling2d_28[0][0]',       \n",
            "                                                                  'activation_227[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)            (None, 32, 32, 16)   4624        ['concatenate_77[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_271 (Batch  (None, 32, 32, 16)  64          ['conv2d_237[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_231 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_271[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_29 (UpSampling2D  (None, 64, 64, 16)  0           ['activation_231[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_78 (Concatenate)   (None, 64, 64, 32)   0           ['up_sampling2d_29[0][0]',       \n",
            "                                                                  'activation_226[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)            (None, 64, 64, 16)   4624        ['concatenate_78[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_272 (Batch  (None, 64, 64, 16)  64          ['conv2d_238[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_232 (Activation)    (None, 64, 64, 16)   0           ['batch_normalization_272[0][0]']\n",
            "                                                                                                  \n",
            " up_sampling2d_30 (UpSampling2D  (None, 128, 128, 16  0          ['activation_232[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_79 (Concatenate)   (None, 128, 128, 32  0           ['up_sampling2d_30[0][0]',       \n",
            "                                )                                 'activation_225[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_79[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_273 (Batch  (None, 128, 128, 16  64         ['conv2d_239[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_233 (Activation)    (None, 128, 128, 16  0           ['batch_normalization_273[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_31 (UpSampling2D  (None, 256, 256, 16  0          ['activation_233[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_80 (Concatenate)   (None, 256, 256, 32  0           ['up_sampling2d_31[0][0]',       \n",
            "                                )                                 'activation_224[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)            (None, 256, 256, 16  4624        ['concatenate_80[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_274 (Batch  (None, 256, 256, 16  64         ['conv2d_240[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_234 (Activation)    (None, 256, 256, 16  0           ['batch_normalization_274[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_32 (UpSampling2D  (None, 512, 512, 16  0          ['activation_234[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_81 (Concatenate)   (None, 512, 512, 32  0           ['up_sampling2d_32[0][0]',       \n",
            "                                )                                 'activation_223[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)            (None, 512, 512, 64  18496       ['concatenate_81[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_275 (Batch  (None, 512, 512, 64  256        ['conv2d_241[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_235 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_275[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_226 (Add)                  (None, 512, 512, 64  0           ['activation_235[0][0]',         \n",
            "                                )                                 'activation_222[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_243 (Conv2D)            (None, 256, 256, 1)  577         ['add_225[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_244 (Conv2D)            (None, 128, 128, 1)  577         ['add_224[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_245 (Conv2D)            (None, 64, 64, 1)    577         ['add_223[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_246 (Conv2D)            (None, 32, 32, 1)    577         ['add_222[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_247 (Conv2D)            (None, 16, 16, 1)    577         ['add_221[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)            (None, 512, 512, 1)  577         ['add_226[0][0]']                \n",
            "                                                                                                  \n",
            " up_sampling2d_33 (UpSampling2D  (None, 512, 512, 1)  0          ['conv2d_243[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_34 (UpSampling2D  (None, 512, 512, 1)  0          ['conv2d_244[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_35 (UpSampling2D  (None, 512, 512, 1)  0          ['conv2d_245[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_36 (UpSampling2D  (None, 512, 512, 1)  0          ['conv2d_246[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_37 (UpSampling2D  (None, 512, 512, 1)  0          ['conv2d_247[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_82 (Concatenate)   (None, 512, 512, 6)  0           ['conv2d_242[0][0]',             \n",
            "                                                                  'up_sampling2d_33[0][0]',       \n",
            "                                                                  'up_sampling2d_34[0][0]',       \n",
            "                                                                  'up_sampling2d_35[0][0]',       \n",
            "                                                                  'up_sampling2d_36[0][0]',       \n",
            "                                                                  'up_sampling2d_37[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_248 (Conv2D)            (None, 512, 512, 1)  55          ['concatenate_82[0][0]']         \n",
            "                                                                                                  \n",
            " activation_236 (Activation)    (None, 512, 512, 1)  0           ['conv2d_248[0][0]']             \n",
            "                                                                                                  \n",
            " activation_237 (Activation)    (None, 512, 512, 1)  0           ['conv2d_242[0][0]']             \n",
            "                                                                                                  \n",
            " activation_238 (Activation)    (None, 512, 512, 1)  0           ['up_sampling2d_33[0][0]']       \n",
            "                                                                                                  \n",
            " activation_239 (Activation)    (None, 512, 512, 1)  0           ['up_sampling2d_34[0][0]']       \n",
            "                                                                                                  \n",
            " activation_240 (Activation)    (None, 512, 512, 1)  0           ['up_sampling2d_35[0][0]']       \n",
            "                                                                                                  \n",
            " activation_241 (Activation)    (None, 512, 512, 1)  0           ['up_sampling2d_36[0][0]']       \n",
            "                                                                                                  \n",
            " activation_242 (Activation)    (None, 512, 512, 1)  0           ['up_sampling2d_37[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,136,925\n",
            "Trainable params: 1,131,229\n",
            "Non-trainable params: 5,696\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UnetR"
      ],
      "metadata": {
        "id": "-DoGz0g7pToc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## sample code to import module\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/folder_name')\n",
        "\n",
        "import my_module"
      ],
      "metadata": {
        "id": "80zFWLw0Dboi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    if not isinstance(hidden_units, list): hidden_units = [hidden_units]\n",
        "    for units in hidden_units:\n",
        "        x = Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = L.LayerNormalization()(x)\n",
        "    x = L.MultiHeadAttention(\n",
        "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
        "    )(x, x)\n",
        "    x = L.Add()([x, skip_1])\n",
        "\n",
        "    skip_2 = x\n",
        "    x = L.LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = L.Add()([x, skip_2])\n",
        "\n",
        "    return x\n",
        "\n",
        "def conv_block(x, num_filters, kernel_size=3):\n",
        "    x = L.Conv2D(num_filters, kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = L.BatchNormalization()(x)\n",
        "    x = L.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def deconv_block(x, num_filters):\n",
        "    x = L.Conv2DTranspose(num_filters, kernel_size=2, padding=\"same\", strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def build_unetr_2d(cf):\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
        "    inputs = L.Input(input_shape) ## (None, 256, 768)\n",
        "\n",
        "    \"\"\" Patch + Position Embeddings \"\"\"\n",
        "    patch_embed = L.Dense(cf[\"hidden_dim\"])(inputs) ## (None, 256, 768)\n",
        "\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1) ## (256,)\n",
        "    pos_embed = L.Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
        "    x = patch_embed + pos_embed ## (None, 256, 768)\n",
        "\n",
        "    \"\"\" Transformer Encoder \"\"\"\n",
        "    skip_connection_index = [3, 6, 9, 12]\n",
        "    skip_connections = []\n",
        "\n",
        "    for i in range(1, cf[\"num_layers\"]+1, 1):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "        if i in skip_connection_index:\n",
        "            skip_connections.append(x)\n",
        "\n",
        "    \"\"\" CNN Decoder \"\"\"\n",
        "    z3, z6, z9, z12 = skip_connections\n",
        "\n",
        "    ## Reshaping\n",
        "    z0 = L.Reshape((cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"]))(inputs)\n",
        "    z3 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z3)\n",
        "    z6 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z6)\n",
        "    z9 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z9)\n",
        "    z12 = L.Reshape((cf[\"patch_size\"], cf[\"patch_size\"], cf[\"hidden_dim\"]))(z12)\n",
        "\n",
        "    ## Decoder 1\n",
        "    x = deconv_block(z12, 512)\n",
        "\n",
        "    s = deconv_block(z9, 512)\n",
        "    s = conv_block(s, 512)\n",
        "    x = L.Concatenate()([x, s])\n",
        "\n",
        "    x = conv_block(x, 512)\n",
        "    x = conv_block(x, 512)\n",
        "\n",
        "    ## Decoder 2\n",
        "    x = deconv_block(x, 256)\n",
        "\n",
        "    s = deconv_block(z6, 256)\n",
        "    s = conv_block(s, 256)\n",
        "    s = deconv_block(s, 256)\n",
        "    s = conv_block(s, 256)\n",
        "\n",
        "    x = L.Concatenate()([x, s])\n",
        "    x = conv_block(x, 256)\n",
        "    x = conv_block(x, 256)\n",
        "\n",
        "    ## Decoder 3\n",
        "    x = deconv_block(x, 128)\n",
        "\n",
        "    s = deconv_block(z3, 128)\n",
        "    s = conv_block(s, 128)\n",
        "    s = deconv_block(s, 128)\n",
        "    s = conv_block(s, 128)\n",
        "    s = deconv_block(s, 128)\n",
        "    s = conv_block(s, 128)\n",
        "\n",
        "    x = L.Concatenate()([x, s])\n",
        "    x = conv_block(x, 128)\n",
        "    x = conv_block(x, 128)\n",
        "\n",
        "    ## Decoder 4\n",
        "    x = deconv_block(x, 64)\n",
        "\n",
        "    s = conv_block(z0, 64)\n",
        "    s = conv_block(s, 64)\n",
        "\n",
        "    x = L.Concatenate()([x, s])\n",
        "    x = conv_block(x, 64)\n",
        "    x = conv_block(x, 64)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = L.Conv2D(1, kernel_size=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
        "\n",
        "    return Model(inputs, outputs, name=\"UNETR_2D\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = {}\n",
        "    config[\"image_size\"] = 256\n",
        "    config[\"num_layers\"] = 12\n",
        "    config[\"hidden_dim\"] = 768\n",
        "    config[\"mlp_dim\"] = 3072\n",
        "    config[\"num_heads\"] = 12\n",
        "    config[\"dropout_rate\"] = 0.1\n",
        "    config[\"num_patches\"] = 256\n",
        "    config[\"patch_size\"] = 16\n",
        "    config[\"num_channels\"] = 3\n",
        "\n",
        "    model = build_unetr_2d(config)\n",
        "    model.summary()"
      ],
      "metadata": {
        "id": "ZjB7RF7LH97z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import (Layer, BatchNormalization, LayerNormalization, Conv2D, Conv2DTranspose, Embedding, \n",
        "    Activation, Dense, Dropout, MultiHeadAttention, add, Input, concatenate, GlobalAveragePooling1D)\n",
        "from keras.models import Model\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    if not isinstance(hidden_units, list): hidden_units = [hidden_units]\n",
        "    for units in hidden_units:\n",
        "        x = Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "class Patches(Layer):\n",
        "    '''\n",
        "    [B, H, W, C] \n",
        "    -> [B, H/patch_size, W/patch_size, C*(patch_size^2)] \n",
        "    -> [B, H*W/(patch_size^2), C*(patch_size^2)]\n",
        "    '''\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = 5\n",
        "        patches = tf.image.extract_patches(\n",
        "            images = images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID',\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "\n",
        "        ##\n",
        "        # height, width = images.shape[:2]    \n",
        "        # patch_height, patch_width = patch_size\n",
        "        \n",
        "        # stride_height = patch_height - overlap\n",
        "        # stride_width = patch_width - overlap\n",
        "        \n",
        "        # patches = []\n",
        "        \n",
        "        # for y in range(0, height-patch_height+1, stride_height):\n",
        "        #     for x in range(0, width-patch_width+1, stride_width):\n",
        "        #         patch = image[y:y+patch_height, x:x+patch_width]\n",
        "        #         patches.append(patch)\n",
        "    \n",
        "\n",
        "\n",
        "        return patches\n",
        "\n",
        "class PatchEncoder(Layer):\n",
        "    '''\n",
        "    Project the patches to projection_dim and introduce learnable positional embedding for patches\n",
        "    '''\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = Dense(units=projection_dim)\n",
        "        self.position_embeding = Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "    \n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embeding(positions)\n",
        "        return encoded\n",
        "\n",
        "def normalization(input_tensor, normalization, name=None):\n",
        "\n",
        "    if normalization=='batch':\n",
        "        return(BatchNormalization(name=None if name is None else name + '_batchnorm')(input_tensor))\n",
        "    elif normalization=='layer':\n",
        "        return(LayerNormalization(epsilon=1e-6, name=None if name is None else name + '_layernorm')(input_tensor))\n",
        "    elif normalization=='group':\n",
        "        return(tfa.layers.GroupNormalization(groups=8, name=None if name is None else name + '_groupnorm')(input_tensor))\n",
        "    elif normalization == None:\n",
        "        return input_tensor\n",
        "    else:\n",
        "        raise ValueError('Invalid normalization')\n",
        "\n",
        "def conv_norm_act(input_tensor, filters, kernel_size , norm_type='batch', act_type='relu', dilation=1):\n",
        "    '''\n",
        "    Conv2d + Normalization(norm_type:str) + Activation(act_type:str)\n",
        "    '''\n",
        "    output_tensor = Conv2D(filters, kernel_size, padding='same', dilation_rate=(dilation, dilation), use_bias=False if norm_type is not None else True, kernel_initializer='he_normal')(input_tensor)\n",
        "    output_tensor = normalization(output_tensor, normalization=norm_type)\n",
        "    if act_type is not None: output_tensor = Activation(act_type)(output_tensor)\n",
        "\n",
        "    return output_tensor\n",
        "\n",
        "def conv2d_block(input_tensor, filters, kernel_size, \n",
        "                norm_type, use_residual, act_type='relu',\n",
        "                double_features = False, dilation=[1, 1], name=None):\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, padding='same', dilation_rate=dilation[0], use_bias=False, kernel_initializer='he_normal', name=None if name is None else name + '_conv2d_0')(input_tensor)\n",
        "    x = normalization(x, norm_type, name=None if name is None else name + '_0')\n",
        "    x = Activation(act_type, name=None if name is None else name + act_type + '_0')(x)\n",
        "\n",
        "    if double_features:\n",
        "        filters *= 2\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, padding='same', dilation_rate=dilation[1], use_bias=False, kernel_initializer='he_normal', name=None if name is None else name + '_conv2d_1')(x)\n",
        "    x = normalization(x, norm_type, name=None if name is None else name + '_1')\n",
        "\n",
        "    if use_residual:\n",
        "        if K.int_shape(input_tensor)[-1] != K.int_shape(x)[-1]:\n",
        "            shortcut = Conv2D(filters, kernel_size=1, padding='same', use_bias=False, kernel_initializer='he_normal', name=None if name is None else name + '_shortcut_conv2d')(input_tensor)\n",
        "            shortcut = normalization(shortcut, norm_type, name=None if name is None else name + '_shortcut')\n",
        "            x = add([x, shortcut])\n",
        "        else:\n",
        "            x = add([x, input_tensor])\n",
        "\n",
        "    x = Activation(act_type, name=None if name is None else name + act_type + '_0')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def deconv_conv_block(x,\n",
        "                      filters_list: list,\n",
        "                      kernel_size,\n",
        "                      norm_type,\n",
        "                      act_type,\n",
        "                      ):\n",
        "    '''\n",
        "    Corresponding to the blue block in the UNETR architecture diagram\n",
        "    '''\n",
        "    for filts in filters_list:\n",
        "        x = Conv2DTranspose(filts, 2, (2, 2), kernel_initializer='he_normal')(x)\n",
        "        x = conv_norm_act(x, filts, kernel_size, norm_type, act_type)\n",
        "    return x\n",
        "\n",
        "def conv_deconv_block(x,\n",
        "                      filters,\n",
        "                      kernel_size,\n",
        "                      norm_type,\n",
        "                      use_residual,\n",
        "                      act_type,\n",
        "                      ):\n",
        "    '''\n",
        "    Corresponding to the yellow + green block in the UNETR architecture diagram\n",
        "    '''\n",
        "    x = conv2d_block(x, filters, kernel_size, norm_type, use_residual, act_type)\n",
        "    x = Conv2DTranspose(filters // 2, 2, (2, 2), kernel_initializer='he_normal')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_vit(x,\n",
        "               patch_size,\n",
        "               num_patches,\n",
        "               projection_dim,\n",
        "               num_heads,\n",
        "               transformer_units,\n",
        "               transformer_layers,\n",
        "               dropout_rate,\n",
        "               extract_layers,\n",
        "               ):\n",
        "    skip_connections = []\n",
        "\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(x)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for layer in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim//num_heads, dropout=dropout_rate\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = add([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=dropout_rate)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = add([x3, x2])\n",
        "        if layer + 1 in extract_layers:\n",
        "            skip_connections.append(encoded_patches)\n",
        "\n",
        "    return skip_connections\n",
        "\n",
        "\n",
        "def build_model(#  Base arguments\n",
        "                input_shape = (512, 512, 3),\n",
        "                class_nums = 2,\n",
        "                #  ViT arguments\n",
        "                patch_size = 32,\n",
        "                projection_dim = 768,\n",
        "                num_heads = 12,\n",
        "                transformer_units = [2048, 768],\n",
        "                transformer_layers = 12,\n",
        "                extract_layers = [3, 6, 9, 12],\n",
        "                dropout_rate = 0.1,\n",
        "                #  Conv arguments\n",
        "                kernel_size = 3,\n",
        "                conv_norm = 'batch',\n",
        "                conv_act = 'relu',\n",
        "                use_residual = False,\n",
        "                #  Other arguments\n",
        "                show_summary = True,\n",
        "                output_act = 'auto',\n",
        "                ):\n",
        "    '''\n",
        "    input_shape: tuple, (height, width, channel) note that this network is used for 2D image segmentation tasks\n",
        "    class_nums: int, output channels\n",
        "    patch_size: int, image partition size\n",
        "    projection_dim: int, pojection dimensions in ViT\n",
        "    num_heads: int, nums of heads for MultiHeadAttention\n",
        "    transformer_units: list, the number of hidden units of the MLP module in ViT, note that it is in the form of a list, should be [hidden units, projection_dims]\n",
        "    transformer_layers: int, transformer stacking nums\n",
        "    extract_layers: list, Determine which layers in ViT should be added to the \"skip connection\", the default is [3, 6, 9, 12]\n",
        "    dropout_rate: float, dropout ratio for the ViT part\n",
        "    kernel_size: int, kernel size for convolution block\n",
        "    conv_norm: str, The normalization method of the convolutional layer, 'batch' or 'layer' or 'group'\n",
        "    conv_act: str, activation function for convilution layer\n",
        "    use_residual: bool, whether the convolution module uses residual connections\n",
        "    show_summary: bool, whether to show the model overview\n",
        "    output_act: str, The activation function of the output layer will be determined according to class_nums when 'auto'\n",
        "      (i.e. 'sigmoid' for binary segmentation task, 'softmax' for multi-class segmentation task)\n",
        "    '''\n",
        "    \n",
        "    z4_de_filts = 512\n",
        "    z3_de_filts_list = [512]\n",
        "    z2_de_filts_list = [512, 256]\n",
        "    z1_de_filts_list = [512, 256, 128]\n",
        "    z34_conv_filts = 512\n",
        "    z23_conv_filts = 256\n",
        "    z12_conv_filts = 128\n",
        "    z01_conv_filts = 64\n",
        "    if output_act == 'auto': output_act = 'sigmoid' if class_nums == 1 else 'softmax'\n",
        "\n",
        "    assert input_shape[0] == input_shape[1] and input_shape[0] // patch_size\n",
        "    num_patches = (input_shape[0] * input_shape[1]) // (patch_size ** 2)\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "    z0 = inputs\n",
        "\n",
        "    z1, z2, z3, z4 = create_vit(z0, \n",
        "                                patch_size,\n",
        "                                num_patches,\n",
        "                                projection_dim,\n",
        "                                num_heads,\n",
        "                                transformer_units,\n",
        "                                transformer_layers,\n",
        "                                dropout_rate,\n",
        "                                extract_layers)\n",
        "    \n",
        "    z1 = tf.reshape(z1, (-1, input_shape[0] // patch_size, input_shape[1] // patch_size, projection_dim)) # [B, H/16, W/16, projection_dim]\n",
        "    z2 = tf.reshape(z2, (-1, input_shape[0] // patch_size, input_shape[1] // patch_size, projection_dim))\n",
        "    z3 = tf.reshape(z3, (-1, input_shape[0] // patch_size, input_shape[1] // patch_size, projection_dim))\n",
        "    z4 = tf.reshape(z4, (-1, input_shape[0] // patch_size, input_shape[1] // patch_size, projection_dim))\n",
        "\n",
        "    z4 = Conv2DTranspose(z4_de_filts, 2, (2, 2), kernel_initializer='he_normal')(z4)\n",
        "    z3 = deconv_conv_block(z3, z3_de_filts_list, kernel_size, conv_norm, conv_act)\n",
        "    z3 = concatenate([z3, z4])\n",
        "    z3 = conv_deconv_block(z3, z34_conv_filts, kernel_size, conv_norm, use_residual, conv_act)\n",
        "    z2 = deconv_conv_block(z2, z2_de_filts_list, kernel_size, conv_norm, conv_act)\n",
        "    z2 = concatenate([z2, z3])\n",
        "    z2 = conv_deconv_block(z2, z23_conv_filts, kernel_size, conv_norm, use_residual, conv_act)\n",
        "    z1 = deconv_conv_block(z1, z1_de_filts_list, kernel_size, conv_norm, conv_act)\n",
        "    z1 = concatenate([z1, z2])\n",
        "    z1 = conv_deconv_block(z1, z12_conv_filts, kernel_size, conv_norm, use_residual, conv_act)\n",
        "    z0 = conv2d_block(z0, z01_conv_filts, kernel_size, conv_norm, use_residual, conv_act)\n",
        "    z0 = concatenate([z0, z1])\n",
        "    z0 = conv2d_block(z0, z01_conv_filts, kernel_size, conv_norm, use_residual, conv_act)\n",
        "\n",
        "    outputs = Conv2D(class_nums, 1, activation=output_act)(z0)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    if show_summary: model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# x = np.random.uniform(size=(1, 512, 512, 3))\n",
        "model = build_model(#  Base arguments\n",
        "          input_shape = (512, 512, 3),\n",
        "          class_nums = 1,\n",
        "          #  ViT arguments\n",
        "          patch_size = 16,\n",
        "          projection_dim = 768,\n",
        "          num_heads = 12,\n",
        "          transformer_units = [2048, 768],\n",
        "          transformer_layers = 12,\n",
        "          extract_layers = [3, 6, 9, 12],\n",
        "          dropout_rate = 0.1,\n",
        "          #  Conv arguments\n",
        "          kernel_size = 3,\n",
        "          conv_norm = 'batch',\n",
        "          conv_act = 'relu',\n",
        "          use_residual = False,\n",
        "          #  Other arguments\n",
        "          show_summary = True,\n",
        "          output_act = 'auto',)\n",
        "# y = model(x)\n",
        "# print(x.shape, y.shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLVl9IUXF2bK",
        "outputId": "a19ff217-947f-4a87-a291-7e9cd6e84f77"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " patches_8 (Patches)            (5, None, 768)       0           ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " patch_encoder_7 (PatchEncoder)  (5, 1024, 768)      1377024     ['patches_8[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_242 (Layer  (5, 1024, 768)      1536        ['patch_encoder_7[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_120 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_242[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_242[0][0]']\n",
            "                                                                                                  \n",
            " add_192 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_120[0][0]'\n",
            "                                                                 , 'patch_encoder_7[0][0]']       \n",
            "                                                                                                  \n",
            " layer_normalization_243 (Layer  (5, 1024, 768)      1536        ['add_192[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_201 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_243[0][0]']\n",
            "                                                                                                  \n",
            " dropout_194 (Dropout)          (5, 1024, 2048)      0           ['dense_201[0][0]']              \n",
            "                                                                                                  \n",
            " dense_202 (Dense)              (5, 1024, 768)       1573632     ['dropout_194[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_195 (Dropout)          (5, 1024, 768)       0           ['dense_202[0][0]']              \n",
            "                                                                                                  \n",
            " add_193 (Add)                  (5, 1024, 768)       0           ['dropout_195[0][0]',            \n",
            "                                                                  'add_192[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_244 (Layer  (5, 1024, 768)      1536        ['add_193[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_121 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_244[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_244[0][0]']\n",
            "                                                                                                  \n",
            " add_194 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_121[0][0]'\n",
            "                                                                 , 'add_193[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_245 (Layer  (5, 1024, 768)      1536        ['add_194[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_203 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_245[0][0]']\n",
            "                                                                                                  \n",
            " dropout_196 (Dropout)          (5, 1024, 2048)      0           ['dense_203[0][0]']              \n",
            "                                                                                                  \n",
            " dense_204 (Dense)              (5, 1024, 768)       1573632     ['dropout_196[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_197 (Dropout)          (5, 1024, 768)       0           ['dense_204[0][0]']              \n",
            "                                                                                                  \n",
            " add_195 (Add)                  (5, 1024, 768)       0           ['dropout_197[0][0]',            \n",
            "                                                                  'add_194[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_246 (Layer  (5, 1024, 768)      1536        ['add_195[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_122 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_246[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_246[0][0]']\n",
            "                                                                                                  \n",
            " add_196 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_122[0][0]'\n",
            "                                                                 , 'add_195[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_247 (Layer  (5, 1024, 768)      1536        ['add_196[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_205 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_247[0][0]']\n",
            "                                                                                                  \n",
            " dropout_198 (Dropout)          (5, 1024, 2048)      0           ['dense_205[0][0]']              \n",
            "                                                                                                  \n",
            " dense_206 (Dense)              (5, 1024, 768)       1573632     ['dropout_198[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_199 (Dropout)          (5, 1024, 768)       0           ['dense_206[0][0]']              \n",
            "                                                                                                  \n",
            " add_197 (Add)                  (5, 1024, 768)       0           ['dropout_199[0][0]',            \n",
            "                                                                  'add_196[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_248 (Layer  (5, 1024, 768)      1536        ['add_197[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_123 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_248[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_248[0][0]']\n",
            "                                                                                                  \n",
            " add_198 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_123[0][0]'\n",
            "                                                                 , 'add_197[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_249 (Layer  (5, 1024, 768)      1536        ['add_198[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_207 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_249[0][0]']\n",
            "                                                                                                  \n",
            " dropout_200 (Dropout)          (5, 1024, 2048)      0           ['dense_207[0][0]']              \n",
            "                                                                                                  \n",
            " dense_208 (Dense)              (5, 1024, 768)       1573632     ['dropout_200[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_201 (Dropout)          (5, 1024, 768)       0           ['dense_208[0][0]']              \n",
            "                                                                                                  \n",
            " add_199 (Add)                  (5, 1024, 768)       0           ['dropout_201[0][0]',            \n",
            "                                                                  'add_198[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_250 (Layer  (5, 1024, 768)      1536        ['add_199[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_124 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_250[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_250[0][0]']\n",
            "                                                                                                  \n",
            " add_200 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_124[0][0]'\n",
            "                                                                 , 'add_199[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_251 (Layer  (5, 1024, 768)      1536        ['add_200[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_209 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_251[0][0]']\n",
            "                                                                                                  \n",
            " dropout_202 (Dropout)          (5, 1024, 2048)      0           ['dense_209[0][0]']              \n",
            "                                                                                                  \n",
            " dense_210 (Dense)              (5, 1024, 768)       1573632     ['dropout_202[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_203 (Dropout)          (5, 1024, 768)       0           ['dense_210[0][0]']              \n",
            "                                                                                                  \n",
            " add_201 (Add)                  (5, 1024, 768)       0           ['dropout_203[0][0]',            \n",
            "                                                                  'add_200[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_252 (Layer  (5, 1024, 768)      1536        ['add_201[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_125 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_252[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_252[0][0]']\n",
            "                                                                                                  \n",
            " add_202 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_125[0][0]'\n",
            "                                                                 , 'add_201[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_253 (Layer  (5, 1024, 768)      1536        ['add_202[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_211 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_253[0][0]']\n",
            "                                                                                                  \n",
            " dropout_204 (Dropout)          (5, 1024, 2048)      0           ['dense_211[0][0]']              \n",
            "                                                                                                  \n",
            " dense_212 (Dense)              (5, 1024, 768)       1573632     ['dropout_204[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_205 (Dropout)          (5, 1024, 768)       0           ['dense_212[0][0]']              \n",
            "                                                                                                  \n",
            " add_203 (Add)                  (5, 1024, 768)       0           ['dropout_205[0][0]',            \n",
            "                                                                  'add_202[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_254 (Layer  (5, 1024, 768)      1536        ['add_203[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_126 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_254[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_254[0][0]']\n",
            "                                                                                                  \n",
            " add_204 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_126[0][0]'\n",
            "                                                                 , 'add_203[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_255 (Layer  (5, 1024, 768)      1536        ['add_204[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_213 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_255[0][0]']\n",
            "                                                                                                  \n",
            " dropout_206 (Dropout)          (5, 1024, 2048)      0           ['dense_213[0][0]']              \n",
            "                                                                                                  \n",
            " dense_214 (Dense)              (5, 1024, 768)       1573632     ['dropout_206[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_207 (Dropout)          (5, 1024, 768)       0           ['dense_214[0][0]']              \n",
            "                                                                                                  \n",
            " add_205 (Add)                  (5, 1024, 768)       0           ['dropout_207[0][0]',            \n",
            "                                                                  'add_204[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_256 (Layer  (5, 1024, 768)      1536        ['add_205[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_127 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_256[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_256[0][0]']\n",
            "                                                                                                  \n",
            " add_206 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_127[0][0]'\n",
            "                                                                 , 'add_205[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_257 (Layer  (5, 1024, 768)      1536        ['add_206[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_215 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_257[0][0]']\n",
            "                                                                                                  \n",
            " dropout_208 (Dropout)          (5, 1024, 2048)      0           ['dense_215[0][0]']              \n",
            "                                                                                                  \n",
            " dense_216 (Dense)              (5, 1024, 768)       1573632     ['dropout_208[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_209 (Dropout)          (5, 1024, 768)       0           ['dense_216[0][0]']              \n",
            "                                                                                                  \n",
            " add_207 (Add)                  (5, 1024, 768)       0           ['dropout_209[0][0]',            \n",
            "                                                                  'add_206[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_258 (Layer  (5, 1024, 768)      1536        ['add_207[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_128 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_258[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_258[0][0]']\n",
            "                                                                                                  \n",
            " add_208 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_128[0][0]'\n",
            "                                                                 , 'add_207[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_259 (Layer  (5, 1024, 768)      1536        ['add_208[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_217 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_259[0][0]']\n",
            "                                                                                                  \n",
            " dropout_210 (Dropout)          (5, 1024, 2048)      0           ['dense_217[0][0]']              \n",
            "                                                                                                  \n",
            " dense_218 (Dense)              (5, 1024, 768)       1573632     ['dropout_210[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_211 (Dropout)          (5, 1024, 768)       0           ['dense_218[0][0]']              \n",
            "                                                                                                  \n",
            " add_209 (Add)                  (5, 1024, 768)       0           ['dropout_211[0][0]',            \n",
            "                                                                  'add_208[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_260 (Layer  (5, 1024, 768)      1536        ['add_209[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_129 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_260[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_260[0][0]']\n",
            "                                                                                                  \n",
            " add_210 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_129[0][0]'\n",
            "                                                                 , 'add_209[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_261 (Layer  (5, 1024, 768)      1536        ['add_210[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_219 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_261[0][0]']\n",
            "                                                                                                  \n",
            " dropout_212 (Dropout)          (5, 1024, 2048)      0           ['dense_219[0][0]']              \n",
            "                                                                                                  \n",
            " dense_220 (Dense)              (5, 1024, 768)       1573632     ['dropout_212[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_213 (Dropout)          (5, 1024, 768)       0           ['dense_220[0][0]']              \n",
            "                                                                                                  \n",
            " add_211 (Add)                  (5, 1024, 768)       0           ['dropout_213[0][0]',            \n",
            "                                                                  'add_210[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_262 (Layer  (5, 1024, 768)      1536        ['add_211[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_130 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_262[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_262[0][0]']\n",
            "                                                                                                  \n",
            " add_212 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_130[0][0]'\n",
            "                                                                 , 'add_211[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_263 (Layer  (5, 1024, 768)      1536        ['add_212[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_221 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_263[0][0]']\n",
            "                                                                                                  \n",
            " dropout_214 (Dropout)          (5, 1024, 2048)      0           ['dense_221[0][0]']              \n",
            "                                                                                                  \n",
            " dense_222 (Dense)              (5, 1024, 768)       1573632     ['dropout_214[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_215 (Dropout)          (5, 1024, 768)       0           ['dense_222[0][0]']              \n",
            "                                                                                                  \n",
            " add_213 (Add)                  (5, 1024, 768)       0           ['dropout_215[0][0]',            \n",
            "                                                                  'add_212[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_264 (Layer  (5, 1024, 768)      1536        ['add_213[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_131 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_264[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_264[0][0]']\n",
            "                                                                                                  \n",
            " add_214 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_131[0][0]'\n",
            "                                                                 , 'add_213[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_265 (Layer  (5, 1024, 768)      1536        ['add_214[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_223 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_265[0][0]']\n",
            "                                                                                                  \n",
            " dropout_216 (Dropout)          (5, 1024, 2048)      0           ['dense_223[0][0]']              \n",
            "                                                                                                  \n",
            " tf.reshape_30 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_209[0][0]']                \n",
            "                                                                                                  \n",
            " dense_224 (Dense)              (5, 1024, 768)       1573632     ['dropout_216[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_71 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_30[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_217 (Dropout)          (5, 1024, 768)       0           ['dense_224[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (5, 64, 64, 512)     2359296     ['conv2d_transpose_71[0][0]']    \n",
            "                                                                                                  \n",
            " add_215 (Add)                  (5, 1024, 768)       0           ['dropout_217[0][0]',            \n",
            "                                                                  'add_214[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (5, 64, 64, 512)    2048        ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_31 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_215[0][0]']                \n",
            "                                                                                                  \n",
            " tf.reshape_29 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_203[0][0]']                \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_70 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_31[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_transpose_73 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_29[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (5, 64, 64, 1024)    0           ['activation_108[0][0]',         \n",
            "                                                                  'conv2d_transpose_70[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (5, 64, 64, 512)     2359296     ['conv2d_transpose_73[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (5, 64, 64, 512)     4718592     ['concatenate_28[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (5, 64, 64, 512)    2048        ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (5, 64, 64, 512)    2048        ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_28 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_197[0][0]']                \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_76 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_28[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_transpose_74 (Conv2DTra  (5, 128, 128, 256)  524544      ['activation_111[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (5, 64, 64, 512)     2359296     ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (5, 64, 64, 512)     2359296     ['conv2d_transpose_76[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (5, 128, 128, 256)   589824      ['conv2d_transpose_74[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (5, 64, 64, 512)    2048        ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (5, 64, 64, 512)    2048        ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (5, 128, 128, 256)  1024        ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_72 (Conv2DTra  (5, 128, 128, 256)  524544      ['activation_110[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_transpose_77 (Conv2DTra  (5, 128, 128, 256)  524544      ['activation_115[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (5, 128, 128, 512)   0           ['activation_112[0][0]',         \n",
            "                                                                  'conv2d_transpose_72[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (5, 128, 128, 256)   589824      ['conv2d_transpose_77[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (5, 128, 128, 256)   1179648     ['concatenate_29[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (5, 128, 128, 256)  1024        ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (5, 128, 128, 256)  1024        ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_78 (Conv2DTra  (5, 256, 256, 128)  131200      ['activation_116[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (5, 128, 128, 256)   589824      ['activation_113[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (5, 256, 256, 128)   147456      ['conv2d_transpose_78[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (5, 128, 128, 256)  1024        ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (5, 256, 256, 128)  512         ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (5, 256, 256, 128)   0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_75 (Conv2DTra  (5, 256, 256, 128)  131200      ['activation_114[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (5, 256, 256, 256)   0           ['activation_117[0][0]',         \n",
            "                                                                  'conv2d_transpose_75[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (5, 256, 256, 128)   294912      ['concatenate_30[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 512, 512, 64  1728        ['input_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (5, 256, 256, 128)  512         ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 512, 512, 64  256        ['conv2d_125[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (5, 256, 256, 128)   0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_160[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (5, 256, 256, 128)   147456      ['activation_118[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 512, 512, 64  36864       ['activation_120[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (5, 256, 256, 128)  512         ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 512, 512, 64  256        ['conv2d_126[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (5, 256, 256, 128)   0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_161[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_79 (Conv2DTra  (5, 512, 512, 64)   32832       ['activation_119[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (5, 512, 512, 128)   0           ['activation_121[0][0]',         \n",
            "                                                                  'conv2d_transpose_79[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (5, 512, 512, 64)    73728       ['concatenate_31[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (5, 512, 512, 64)   256         ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (5, 512, 512, 64)    0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (5, 512, 512, 64)    36864       ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (5, 512, 512, 64)   256         ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (5, 512, 512, 64)    0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (5, 512, 512, 1)     65          ['activation_123[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93,568,065\n",
            "Trainable params: 93,559,617\n",
            "Non-trainable params: 8,448\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " patches_8 (Patches)            (5, None, 768)       0           ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " patch_encoder_7 (PatchEncoder)  (5, 1024, 768)      1377024     ['patches_8[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_242 (Layer  (5, 1024, 768)      1536        ['patch_encoder_7[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_120 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_242[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_242[0][0]']\n",
            "                                                                                                  \n",
            " add_192 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_120[0][0]'\n",
            "                                                                 , 'patch_encoder_7[0][0]']       \n",
            "                                                                                                  \n",
            " layer_normalization_243 (Layer  (5, 1024, 768)      1536        ['add_192[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_201 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_243[0][0]']\n",
            "                                                                                                  \n",
            " dropout_194 (Dropout)          (5, 1024, 2048)      0           ['dense_201[0][0]']              \n",
            "                                                                                                  \n",
            " dense_202 (Dense)              (5, 1024, 768)       1573632     ['dropout_194[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_195 (Dropout)          (5, 1024, 768)       0           ['dense_202[0][0]']              \n",
            "                                                                                                  \n",
            " add_193 (Add)                  (5, 1024, 768)       0           ['dropout_195[0][0]',            \n",
            "                                                                  'add_192[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_244 (Layer  (5, 1024, 768)      1536        ['add_193[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_121 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_244[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_244[0][0]']\n",
            "                                                                                                  \n",
            " add_194 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_121[0][0]'\n",
            "                                                                 , 'add_193[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_245 (Layer  (5, 1024, 768)      1536        ['add_194[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_203 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_245[0][0]']\n",
            "                                                                                                  \n",
            " dropout_196 (Dropout)          (5, 1024, 2048)      0           ['dense_203[0][0]']              \n",
            "                                                                                                  \n",
            " dense_204 (Dense)              (5, 1024, 768)       1573632     ['dropout_196[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_197 (Dropout)          (5, 1024, 768)       0           ['dense_204[0][0]']              \n",
            "                                                                                                  \n",
            " add_195 (Add)                  (5, 1024, 768)       0           ['dropout_197[0][0]',            \n",
            "                                                                  'add_194[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_246 (Layer  (5, 1024, 768)      1536        ['add_195[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_122 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_246[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_246[0][0]']\n",
            "                                                                                                  \n",
            " add_196 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_122[0][0]'\n",
            "                                                                 , 'add_195[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_247 (Layer  (5, 1024, 768)      1536        ['add_196[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_205 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_247[0][0]']\n",
            "                                                                                                  \n",
            " dropout_198 (Dropout)          (5, 1024, 2048)      0           ['dense_205[0][0]']              \n",
            "                                                                                                  \n",
            " dense_206 (Dense)              (5, 1024, 768)       1573632     ['dropout_198[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_199 (Dropout)          (5, 1024, 768)       0           ['dense_206[0][0]']              \n",
            "                                                                                                  \n",
            " add_197 (Add)                  (5, 1024, 768)       0           ['dropout_199[0][0]',            \n",
            "                                                                  'add_196[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_248 (Layer  (5, 1024, 768)      1536        ['add_197[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_123 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_248[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_248[0][0]']\n",
            "                                                                                                  \n",
            " add_198 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_123[0][0]'\n",
            "                                                                 , 'add_197[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_249 (Layer  (5, 1024, 768)      1536        ['add_198[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_207 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_249[0][0]']\n",
            "                                                                                                  \n",
            " dropout_200 (Dropout)          (5, 1024, 2048)      0           ['dense_207[0][0]']              \n",
            "                                                                                                  \n",
            " dense_208 (Dense)              (5, 1024, 768)       1573632     ['dropout_200[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_201 (Dropout)          (5, 1024, 768)       0           ['dense_208[0][0]']              \n",
            "                                                                                                  \n",
            " add_199 (Add)                  (5, 1024, 768)       0           ['dropout_201[0][0]',            \n",
            "                                                                  'add_198[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_250 (Layer  (5, 1024, 768)      1536        ['add_199[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_124 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_250[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_250[0][0]']\n",
            "                                                                                                  \n",
            " add_200 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_124[0][0]'\n",
            "                                                                 , 'add_199[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_251 (Layer  (5, 1024, 768)      1536        ['add_200[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_209 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_251[0][0]']\n",
            "                                                                                                  \n",
            " dropout_202 (Dropout)          (5, 1024, 2048)      0           ['dense_209[0][0]']              \n",
            "                                                                                                  \n",
            " dense_210 (Dense)              (5, 1024, 768)       1573632     ['dropout_202[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_203 (Dropout)          (5, 1024, 768)       0           ['dense_210[0][0]']              \n",
            "                                                                                                  \n",
            " add_201 (Add)                  (5, 1024, 768)       0           ['dropout_203[0][0]',            \n",
            "                                                                  'add_200[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_252 (Layer  (5, 1024, 768)      1536        ['add_201[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_125 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_252[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_252[0][0]']\n",
            "                                                                                                  \n",
            " add_202 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_125[0][0]'\n",
            "                                                                 , 'add_201[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_253 (Layer  (5, 1024, 768)      1536        ['add_202[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_211 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_253[0][0]']\n",
            "                                                                                                  \n",
            " dropout_204 (Dropout)          (5, 1024, 2048)      0           ['dense_211[0][0]']              \n",
            "                                                                                                  \n",
            " dense_212 (Dense)              (5, 1024, 768)       1573632     ['dropout_204[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_205 (Dropout)          (5, 1024, 768)       0           ['dense_212[0][0]']              \n",
            "                                                                                                  \n",
            " add_203 (Add)                  (5, 1024, 768)       0           ['dropout_205[0][0]',            \n",
            "                                                                  'add_202[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_254 (Layer  (5, 1024, 768)      1536        ['add_203[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_126 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_254[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_254[0][0]']\n",
            "                                                                                                  \n",
            " add_204 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_126[0][0]'\n",
            "                                                                 , 'add_203[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_255 (Layer  (5, 1024, 768)      1536        ['add_204[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_213 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_255[0][0]']\n",
            "                                                                                                  \n",
            " dropout_206 (Dropout)          (5, 1024, 2048)      0           ['dense_213[0][0]']              \n",
            "                                                                                                  \n",
            " dense_214 (Dense)              (5, 1024, 768)       1573632     ['dropout_206[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_207 (Dropout)          (5, 1024, 768)       0           ['dense_214[0][0]']              \n",
            "                                                                                                  \n",
            " add_205 (Add)                  (5, 1024, 768)       0           ['dropout_207[0][0]',            \n",
            "                                                                  'add_204[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_256 (Layer  (5, 1024, 768)      1536        ['add_205[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_127 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_256[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_256[0][0]']\n",
            "                                                                                                  \n",
            " add_206 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_127[0][0]'\n",
            "                                                                 , 'add_205[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_257 (Layer  (5, 1024, 768)      1536        ['add_206[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_215 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_257[0][0]']\n",
            "                                                                                                  \n",
            " dropout_208 (Dropout)          (5, 1024, 2048)      0           ['dense_215[0][0]']              \n",
            "                                                                                                  \n",
            " dense_216 (Dense)              (5, 1024, 768)       1573632     ['dropout_208[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_209 (Dropout)          (5, 1024, 768)       0           ['dense_216[0][0]']              \n",
            "                                                                                                  \n",
            " add_207 (Add)                  (5, 1024, 768)       0           ['dropout_209[0][0]',            \n",
            "                                                                  'add_206[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_258 (Layer  (5, 1024, 768)      1536        ['add_207[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_128 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_258[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_258[0][0]']\n",
            "                                                                                                  \n",
            " add_208 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_128[0][0]'\n",
            "                                                                 , 'add_207[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_259 (Layer  (5, 1024, 768)      1536        ['add_208[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_217 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_259[0][0]']\n",
            "                                                                                                  \n",
            " dropout_210 (Dropout)          (5, 1024, 2048)      0           ['dense_217[0][0]']              \n",
            "                                                                                                  \n",
            " dense_218 (Dense)              (5, 1024, 768)       1573632     ['dropout_210[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_211 (Dropout)          (5, 1024, 768)       0           ['dense_218[0][0]']              \n",
            "                                                                                                  \n",
            " add_209 (Add)                  (5, 1024, 768)       0           ['dropout_211[0][0]',            \n",
            "                                                                  'add_208[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_260 (Layer  (5, 1024, 768)      1536        ['add_209[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_129 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_260[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_260[0][0]']\n",
            "                                                                                                  \n",
            " add_210 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_129[0][0]'\n",
            "                                                                 , 'add_209[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_261 (Layer  (5, 1024, 768)      1536        ['add_210[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_219 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_261[0][0]']\n",
            "                                                                                                  \n",
            " dropout_212 (Dropout)          (5, 1024, 2048)      0           ['dense_219[0][0]']              \n",
            "                                                                                                  \n",
            " dense_220 (Dense)              (5, 1024, 768)       1573632     ['dropout_212[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_213 (Dropout)          (5, 1024, 768)       0           ['dense_220[0][0]']              \n",
            "                                                                                                  \n",
            " add_211 (Add)                  (5, 1024, 768)       0           ['dropout_213[0][0]',            \n",
            "                                                                  'add_210[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_262 (Layer  (5, 1024, 768)      1536        ['add_211[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_130 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_262[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_262[0][0]']\n",
            "                                                                                                  \n",
            " add_212 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_130[0][0]'\n",
            "                                                                 , 'add_211[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_263 (Layer  (5, 1024, 768)      1536        ['add_212[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_221 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_263[0][0]']\n",
            "                                                                                                  \n",
            " dropout_214 (Dropout)          (5, 1024, 2048)      0           ['dense_221[0][0]']              \n",
            "                                                                                                  \n",
            " dense_222 (Dense)              (5, 1024, 768)       1573632     ['dropout_214[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_215 (Dropout)          (5, 1024, 768)       0           ['dense_222[0][0]']              \n",
            "                                                                                                  \n",
            " add_213 (Add)                  (5, 1024, 768)       0           ['dropout_215[0][0]',            \n",
            "                                                                  'add_212[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_264 (Layer  (5, 1024, 768)      1536        ['add_213[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_131 (Mult  (5, 1024, 768)      2362368     ['layer_normalization_264[0][0]',\n",
            " iHeadAttention)                                                  'layer_normalization_264[0][0]']\n",
            "                                                                                                  \n",
            " add_214 (Add)                  (5, 1024, 768)       0           ['multi_head_attention_131[0][0]'\n",
            "                                                                 , 'add_213[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_265 (Layer  (5, 1024, 768)      1536        ['add_214[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_223 (Dense)              (5, 1024, 2048)      1574912     ['layer_normalization_265[0][0]']\n",
            "                                                                                                  \n",
            " dropout_216 (Dropout)          (5, 1024, 2048)      0           ['dense_223[0][0]']              \n",
            "                                                                                                  \n",
            " tf.reshape_30 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_209[0][0]']                \n",
            "                                                                                                  \n",
            " dense_224 (Dense)              (5, 1024, 768)       1573632     ['dropout_216[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_71 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_30[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_217 (Dropout)          (5, 1024, 768)       0           ['dense_224[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (5, 64, 64, 512)     2359296     ['conv2d_transpose_71[0][0]']    \n",
            "                                                                                                  \n",
            " add_215 (Add)                  (5, 1024, 768)       0           ['dropout_217[0][0]',            \n",
            "                                                                  'add_214[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (5, 64, 64, 512)    2048        ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_31 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_215[0][0]']                \n",
            "                                                                                                  \n",
            " tf.reshape_29 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_203[0][0]']                \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_70 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_31[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_transpose_73 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_29[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (5, 64, 64, 1024)    0           ['activation_108[0][0]',         \n",
            "                                                                  'conv2d_transpose_70[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (5, 64, 64, 512)     2359296     ['conv2d_transpose_73[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (5, 64, 64, 512)     4718592     ['concatenate_28[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (5, 64, 64, 512)    2048        ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (5, 64, 64, 512)    2048        ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_28 (TFOpLambda)     (5, 32, 32, 768)     0           ['add_197[0][0]']                \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_76 (Conv2DTra  (5, 64, 64, 512)    1573376     ['tf.reshape_28[0][0]']          \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_transpose_74 (Conv2DTra  (5, 128, 128, 256)  524544      ['activation_111[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (5, 64, 64, 512)     2359296     ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (5, 64, 64, 512)     2359296     ['conv2d_transpose_76[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (5, 128, 128, 256)   589824      ['conv2d_transpose_74[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (5, 64, 64, 512)    2048        ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (5, 64, 64, 512)    2048        ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (5, 128, 128, 256)  1024        ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (5, 64, 64, 512)     0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_72 (Conv2DTra  (5, 128, 128, 256)  524544      ['activation_110[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_transpose_77 (Conv2DTra  (5, 128, 128, 256)  524544      ['activation_115[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (5, 128, 128, 512)   0           ['activation_112[0][0]',         \n",
            "                                                                  'conv2d_transpose_72[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (5, 128, 128, 256)   589824      ['conv2d_transpose_77[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (5, 128, 128, 256)   1179648     ['concatenate_29[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (5, 128, 128, 256)  1024        ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (5, 128, 128, 256)  1024        ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_78 (Conv2DTra  (5, 256, 256, 128)  131200      ['activation_116[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (5, 128, 128, 256)   589824      ['activation_113[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (5, 256, 256, 128)   147456      ['conv2d_transpose_78[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (5, 128, 128, 256)  1024        ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (5, 256, 256, 128)  512         ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (5, 128, 128, 256)   0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (5, 256, 256, 128)   0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_75 (Conv2DTra  (5, 256, 256, 128)  131200      ['activation_114[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (5, 256, 256, 256)   0           ['activation_117[0][0]',         \n",
            "                                                                  'conv2d_transpose_75[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (5, 256, 256, 128)   294912      ['concatenate_30[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 512, 512, 64  1728        ['input_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (5, 256, 256, 128)  512         ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 512, 512, 64  256        ['conv2d_125[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (5, 256, 256, 128)   0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_160[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (5, 256, 256, 128)   147456      ['activation_118[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 512, 512, 64  36864       ['activation_120[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (5, 256, 256, 128)  512         ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 512, 512, 64  256        ['conv2d_126[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (5, 256, 256, 128)   0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_161[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_79 (Conv2DTra  (5, 512, 512, 64)   32832       ['activation_119[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (5, 512, 512, 128)   0           ['activation_121[0][0]',         \n",
            "                                                                  'conv2d_transpose_79[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (5, 512, 512, 64)    73728       ['concatenate_31[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (5, 512, 512, 64)   256         ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (5, 512, 512, 64)    0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (5, 512, 512, 64)    36864       ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (5, 512, 512, 64)   256         ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (5, 512, 512, 64)    0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (5, 512, 512, 1)     65          ['activation_123[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93,568,065\n",
            "Trainable params: 93,559,617\n",
            "Non-trainable params: 8,448\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vgg19 Unet"
      ],
      "metadata": {
        "id": "idSsER7NdVSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_vgg19_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained VGG19 Model \"\"\"\n",
        "    vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = vgg19.get_layer(\"block1_conv2\").output         ## (512 x 512)\n",
        "    s2 = vgg19.get_layer(\"block2_conv2\").output         ## (256 x 256)\n",
        "    s3 = vgg19.get_layer(\"block3_conv4\").output         ## (128 x 128)\n",
        "    s4 = vgg19.get_layer(\"block4_conv4\").output         ## (64 x 64)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = vgg19.get_layer(\"block5_conv4\").output         ## (32 x 32)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = (512, 512, 3)\n",
        "model = build_vgg19_unet(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI2g-bojdWI-",
        "outputId": "7a302c5f-9cbb-423c-d09c-0c88a49523b1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"VGG19_U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 512, 512, 64  1792        ['input_14[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 512, 512, 64  36928       ['block1_conv1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 256, 256, 64  0           ['block1_conv2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 256, 256, 12  73856       ['block1_pool[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 256, 256, 12  147584      ['block2_conv1[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 128, 128, 12  0           ['block2_conv2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 128, 128, 25  295168      ['block2_pool[0][0]']            \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv1[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv2[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_conv4 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv3[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 64, 64, 256)  0           ['block3_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 64, 64, 512)  1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv4 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 32, 32, 512)  0           ['block4_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 32, 32, 512)  2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv4 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_88 (Conv2DTra  (None, 64, 64, 512)  1049088    ['block5_conv4[0][0]']           \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_91 (Concatenate)   (None, 64, 64, 1024  0           ['conv2d_transpose_88[0][0]',    \n",
            "                                )                                 'block4_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_267 (Conv2D)            (None, 64, 64, 512)  4719104     ['concatenate_91[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_292 (Batch  (None, 64, 64, 512)  2048       ['conv2d_267[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_259 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_292[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_268 (Conv2D)            (None, 64, 64, 512)  2359808     ['activation_259[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_293 (Batch  (None, 64, 64, 512)  2048       ['conv2d_268[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_260 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_293[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_89 (Conv2DTra  (None, 128, 128, 25  524544     ['activation_260[0][0]']         \n",
            " nspose)                        6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_92 (Concatenate)   (None, 128, 128, 51  0           ['conv2d_transpose_89[0][0]',    \n",
            "                                2)                                'block3_conv4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_269 (Conv2D)            (None, 128, 128, 25  1179904     ['concatenate_92[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_294 (Batch  (None, 128, 128, 25  1024       ['conv2d_269[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_261 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_294[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_270 (Conv2D)            (None, 128, 128, 25  590080      ['activation_261[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_295 (Batch  (None, 128, 128, 25  1024       ['conv2d_270[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_262 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_295[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_90 (Conv2DTra  (None, 256, 256, 12  131200     ['activation_262[0][0]']         \n",
            " nspose)                        8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_93 (Concatenate)   (None, 256, 256, 25  0           ['conv2d_transpose_90[0][0]',    \n",
            "                                6)                                'block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_271 (Conv2D)            (None, 256, 256, 12  295040      ['concatenate_93[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_296 (Batch  (None, 256, 256, 12  512        ['conv2d_271[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_263 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_296[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_272 (Conv2D)            (None, 256, 256, 12  147584      ['activation_263[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_297 (Batch  (None, 256, 256, 12  512        ['conv2d_272[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_264 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_297[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_91 (Conv2DTra  (None, 512, 512, 64  32832      ['activation_264[0][0]']         \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_94 (Concatenate)   (None, 512, 512, 12  0           ['conv2d_transpose_91[0][0]',    \n",
            "                                8)                                'block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_273 (Conv2D)            (None, 512, 512, 64  73792       ['concatenate_94[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_298 (Batch  (None, 512, 512, 64  256        ['conv2d_273[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_265 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_298[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_274 (Conv2D)            (None, 512, 512, 64  36928       ['activation_265[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_299 (Batch  (None, 512, 512, 64  256        ['conv2d_274[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_266 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_299[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_275 (Conv2D)            (None, 512, 512, 1)  65          ['activation_266[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,172,033\n",
            "Trainable params: 31,168,193\n",
            "Non-trainable params: 3,840\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training & Compile"
      ],
      "metadata": {
        "id": "PWJXYDX12HU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_true, y_pred):\n",
        "    def dice_loss(y_true, y_pred):\n",
        "        y_pred = tf.math.sigmoid(y_pred)\n",
        "        numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "        denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "        return 1 - numerator / denominator\n",
        "\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    o = tf.nn.sigmoid_cross_entropy_with_logits(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return tf.reduce_mean(o)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:51.099942Z",
          "iopub.execute_input": "2023-05-24T11:53:51.100735Z",
          "iopub.status.idle": "2023-05-24T11:53:51.106856Z",
          "shell.execute_reply.started": "2023-05-24T11:53:51.100698Z",
          "shell.execute_reply": "2023-05-24T11:53:51.105864Z"
        },
        "trusted": true,
        "id": "7bPL3BMbntSr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity_loss(y_true, y_pred):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
        "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2]) - intersection\n",
        "    jaccard = intersection / (union + tf.keras.backend.epsilon())\n",
        "    loss = 1 - jaccard\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Yl5K4gDOnqD6"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure the optimizer, loss and metrics for training\n",
        "\n",
        "# metrics : iou, accuracy\n",
        "model.compile(\n",
        "              # tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              # optimizer='adam',\n",
        "              optimizer = tf.keras.optimizers.experimental.SGD(0.01, momentum=0.9, weight_decay=0.0001),\n",
        "              # loss=loss,\n",
        "              loss = jaccard_similarity_loss,\n",
        "#               loss = dice_loss,\n",
        "#               loss='binary_crossentropy',\n",
        "              metrics=[tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0]), 'accuracy', tf.keras.metrics.MeanIoU(num_classes=2)]) # 1 is the target "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:52.519967Z",
          "iopub.execute_input": "2023-05-24T11:53:52.520677Z",
          "iopub.status.idle": "2023-05-24T11:53:52.543017Z",
          "shell.execute_reply.started": "2023-05-24T11:53:52.520641Z",
          "shell.execute_reply": "2023-05-24T11:53:52.542037Z"
        },
        "trusted": true,
        "id": "MFbeUH3XntSr"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [ModelCheckpoint(model_file, verbose=1, save_best_only = True),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "             CSVLogger(log_file),\n",
        "             EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "             ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:53.443191Z",
          "iopub.execute_input": "2023-05-24T11:53:53.443595Z",
          "iopub.status.idle": "2023-05-24T11:53:53.449901Z",
          "shell.execute_reply.started": "2023-05-24T11:53:53.443565Z",
          "shell.execute_reply": "2023-05-24T11:53:53.448958Z"
        },
        "trusted": true,
        "id": "LiF3WpZ3ntSr"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st run\n",
        "history = model.fit(train_patch_generator,\n",
        "                    # train_generator, \n",
        "                    epochs=50, \n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=val_patch_generator,\n",
        "                    steps_per_epoch = 2*140/BATCH_SIZE,\n",
        "                    validation_steps = 40/BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T11:53:55.193091Z",
          "iopub.execute_input": "2023-05-24T11:53:55.193508Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56jKrXm4ntSr",
        "outputId": "541ff93e-0bcc-4120-c236-77accb308a5b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6709 - io_u_7: 0.8555 - accuracy: 0.8668 - mean_io_u_7: 0.4976\n",
            "Epoch 1: val_loss improved from inf to 0.85132, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 32s 470ms/step - loss: 0.6709 - io_u_7: 0.8555 - accuracy: 0.8668 - mean_io_u_7: 0.4976 - val_loss: 0.8513 - val_io_u_7: 0.7539 - val_accuracy: 0.2967 - val_mean_io_u_7: 0.5337 - lr: 0.1000\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6711 - io_u_7: 0.8604 - accuracy: 0.8647 - mean_io_u_7: 0.5229\n",
            "Epoch 2: val_loss did not improve from 0.85132\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6711 - io_u_7: 0.8604 - accuracy: 0.8647 - mean_io_u_7: 0.5229 - val_loss: 0.9775 - val_io_u_7: 0.8233 - val_accuracy: 0.8263 - val_mean_io_u_7: 0.4117 - lr: 0.1000\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6637 - io_u_7: 0.8534 - accuracy: 0.8530 - mean_io_u_7: 0.5326\n",
            "Epoch 3: val_loss improved from 0.85132 to 0.83732, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 25s 461ms/step - loss: 0.6637 - io_u_7: 0.8534 - accuracy: 0.8530 - mean_io_u_7: 0.5326 - val_loss: 0.8373 - val_io_u_7: 0.7680 - val_accuracy: 0.3575 - val_mean_io_u_7: 0.5582 - lr: 0.1000\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6607 - io_u_7: 0.8765 - accuracy: 0.8649 - mean_io_u_7: 0.5619\n",
            "Epoch 4: val_loss did not improve from 0.83732\n",
            "56/56 [==============================] - 25s 448ms/step - loss: 0.6607 - io_u_7: 0.8765 - accuracy: 0.8649 - mean_io_u_7: 0.5619 - val_loss: 0.9879 - val_io_u_7: 0.8279 - val_accuracy: 0.8302 - val_mean_io_u_7: 0.4141 - lr: 0.1000\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6647 - io_u_7: 0.8712 - accuracy: 0.8580 - mean_io_u_7: 0.5632\n",
            "Epoch 5: val_loss improved from 0.83732 to 0.66392, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 467ms/step - loss: 0.6647 - io_u_7: 0.8712 - accuracy: 0.8580 - mean_io_u_7: 0.5632 - val_loss: 0.6639 - val_io_u_7: 0.8477 - val_accuracy: 0.7457 - val_mean_io_u_7: 0.5905 - lr: 0.1000\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.7002 - io_u_7: 0.8798 - accuracy: 0.8600 - mean_io_u_7: 0.5678\n",
            "Epoch 6: val_loss did not improve from 0.66392\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.7002 - io_u_7: 0.8798 - accuracy: 0.8600 - mean_io_u_7: 0.5678 - val_loss: 0.7239 - val_io_u_7: 0.8752 - val_accuracy: 0.9094 - val_mean_io_u_7: 0.4939 - lr: 0.1000\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6602 - io_u_7: 0.8714 - accuracy: 0.8571 - mean_io_u_7: 0.5706\n",
            "Epoch 7: val_loss did not improve from 0.66392\n",
            "56/56 [==============================] - 25s 451ms/step - loss: 0.6602 - io_u_7: 0.8714 - accuracy: 0.8571 - mean_io_u_7: 0.5706 - val_loss: 0.7177 - val_io_u_7: 0.8620 - val_accuracy: 0.7483 - val_mean_io_u_7: 0.6617 - lr: 0.1000\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6693 - io_u_7: 0.8686 - accuracy: 0.8459 - mean_io_u_7: 0.5699\n",
            "Epoch 8: val_loss did not improve from 0.66392\n",
            "56/56 [==============================] - 25s 448ms/step - loss: 0.6693 - io_u_7: 0.8686 - accuracy: 0.8459 - mean_io_u_7: 0.5699 - val_loss: 0.7676 - val_io_u_7: 0.8660 - val_accuracy: 0.6587 - val_mean_io_u_7: 0.5839 - lr: 0.1000\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6718 - io_u_7: 0.8898 - accuracy: 0.8786 - mean_io_u_7: 0.5888\n",
            "Epoch 9: val_loss did not improve from 0.66392\n",
            "56/56 [==============================] - 25s 456ms/step - loss: 0.6718 - io_u_7: 0.8898 - accuracy: 0.8786 - mean_io_u_7: 0.5888 - val_loss: 0.6656 - val_io_u_7: 0.8686 - val_accuracy: 0.8920 - val_mean_io_u_7: 0.5897 - lr: 0.1000\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6595 - io_u_7: 0.8763 - accuracy: 0.8681 - mean_io_u_7: 0.5987\n",
            "Epoch 10: val_loss did not improve from 0.66392\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6595 - io_u_7: 0.8763 - accuracy: 0.8681 - mean_io_u_7: 0.5987 - val_loss: 0.7039 - val_io_u_7: 0.9006 - val_accuracy: 0.9258 - val_mean_io_u_7: 0.5892 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6602 - io_u_7: 0.8904 - accuracy: 0.8764 - mean_io_u_7: 0.6048\n",
            "Epoch 11: val_loss improved from 0.66392 to 0.59998, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 466ms/step - loss: 0.6602 - io_u_7: 0.8904 - accuracy: 0.8764 - mean_io_u_7: 0.6048 - val_loss: 0.6000 - val_io_u_7: 0.8899 - val_accuracy: 0.8827 - val_mean_io_u_7: 0.6735 - lr: 0.0100\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6473 - io_u_7: 0.8802 - accuracy: 0.8796 - mean_io_u_7: 0.5951\n",
            "Epoch 12: val_loss did not improve from 0.59998\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6473 - io_u_7: 0.8802 - accuracy: 0.8796 - mean_io_u_7: 0.5951 - val_loss: 0.7512 - val_io_u_7: 0.8096 - val_accuracy: 0.8443 - val_mean_io_u_7: 0.4423 - lr: 0.0100\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6466 - io_u_7: 0.8708 - accuracy: 0.8678 - mean_io_u_7: 0.5816\n",
            "Epoch 13: val_loss improved from 0.59998 to 0.58340, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 467ms/step - loss: 0.6466 - io_u_7: 0.8708 - accuracy: 0.8678 - mean_io_u_7: 0.5816 - val_loss: 0.5834 - val_io_u_7: 0.8865 - val_accuracy: 0.8893 - val_mean_io_u_7: 0.6214 - lr: 0.0100\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6461 - io_u_7: 0.8818 - accuracy: 0.8816 - mean_io_u_7: 0.5957\n",
            "Epoch 14: val_loss improved from 0.58340 to 0.58108, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 463ms/step - loss: 0.6461 - io_u_7: 0.8818 - accuracy: 0.8816 - mean_io_u_7: 0.5957 - val_loss: 0.5811 - val_io_u_7: 0.8525 - val_accuracy: 0.8955 - val_mean_io_u_7: 0.5696 - lr: 0.0100\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6141 - io_u_7: 0.8728 - accuracy: 0.8739 - mean_io_u_7: 0.5882\n",
            "Epoch 15: val_loss did not improve from 0.58108\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6141 - io_u_7: 0.8728 - accuracy: 0.8739 - mean_io_u_7: 0.5882 - val_loss: 0.6321 - val_io_u_7: 0.8941 - val_accuracy: 0.9155 - val_mean_io_u_7: 0.5721 - lr: 0.0100\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6488 - io_u_7: 0.8755 - accuracy: 0.8703 - mean_io_u_7: 0.5842\n",
            "Epoch 16: val_loss did not improve from 0.58108\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6488 - io_u_7: 0.8755 - accuracy: 0.8703 - mean_io_u_7: 0.5842 - val_loss: 0.5886 - val_io_u_7: 0.8872 - val_accuracy: 0.9144 - val_mean_io_u_7: 0.5902 - lr: 0.0100\n",
            "Epoch 17/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6574 - io_u_7: 0.8850 - accuracy: 0.8823 - mean_io_u_7: 0.6011\n",
            "Epoch 17: val_loss did not improve from 0.58108\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6574 - io_u_7: 0.8850 - accuracy: 0.8823 - mean_io_u_7: 0.6011 - val_loss: 0.6433 - val_io_u_7: 0.8550 - val_accuracy: 0.8998 - val_mean_io_u_7: 0.5402 - lr: 0.0100\n",
            "Epoch 18/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6189 - io_u_7: 0.8849 - accuracy: 0.8854 - mean_io_u_7: 0.6043\n",
            "Epoch 18: val_loss did not improve from 0.58108\n",
            "56/56 [==============================] - 25s 451ms/step - loss: 0.6189 - io_u_7: 0.8849 - accuracy: 0.8854 - mean_io_u_7: 0.6043 - val_loss: 0.6015 - val_io_u_7: 0.8939 - val_accuracy: 0.9222 - val_mean_io_u_7: 0.6009 - lr: 0.0100\n",
            "Epoch 19/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6338 - io_u_7: 0.8827 - accuracy: 0.8881 - mean_io_u_7: 0.5925\n",
            "Epoch 19: val_loss did not improve from 0.58108\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6338 - io_u_7: 0.8827 - accuracy: 0.8881 - mean_io_u_7: 0.5925 - val_loss: 0.5894 - val_io_u_7: 0.9027 - val_accuracy: 0.9153 - val_mean_io_u_7: 0.6776 - lr: 1.0000e-03\n",
            "Epoch 20/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6211 - io_u_7: 0.8701 - accuracy: 0.8823 - mean_io_u_7: 0.5854\n",
            "Epoch 20: val_loss improved from 0.58108 to 0.54992, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 464ms/step - loss: 0.6211 - io_u_7: 0.8701 - accuracy: 0.8823 - mean_io_u_7: 0.5854 - val_loss: 0.5499 - val_io_u_7: 0.8299 - val_accuracy: 0.8815 - val_mean_io_u_7: 0.5779 - lr: 1.0000e-03\n",
            "Epoch 21/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6116 - io_u_7: 0.8914 - accuracy: 0.8957 - mean_io_u_7: 0.6154\n",
            "Epoch 21: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 460ms/step - loss: 0.6116 - io_u_7: 0.8914 - accuracy: 0.8957 - mean_io_u_7: 0.6154 - val_loss: 0.5762 - val_io_u_7: 0.8853 - val_accuracy: 0.9152 - val_mean_io_u_7: 0.6082 - lr: 1.0000e-03\n",
            "Epoch 22/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6048 - io_u_7: 0.8658 - accuracy: 0.8791 - mean_io_u_7: 0.5788\n",
            "Epoch 22: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 451ms/step - loss: 0.6048 - io_u_7: 0.8658 - accuracy: 0.8791 - mean_io_u_7: 0.5788 - val_loss: 0.5928 - val_io_u_7: 0.8668 - val_accuracy: 0.8760 - val_mean_io_u_7: 0.6179 - lr: 1.0000e-03\n",
            "Epoch 23/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6335 - io_u_7: 0.8861 - accuracy: 0.8891 - mean_io_u_7: 0.6023\n",
            "Epoch 23: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 451ms/step - loss: 0.6335 - io_u_7: 0.8861 - accuracy: 0.8891 - mean_io_u_7: 0.6023 - val_loss: 0.6149 - val_io_u_7: 0.8986 - val_accuracy: 0.9041 - val_mean_io_u_7: 0.6655 - lr: 1.0000e-03\n",
            "Epoch 24/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.5909 - io_u_7: 0.8683 - accuracy: 0.8842 - mean_io_u_7: 0.5834\n",
            "Epoch 24: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 453ms/step - loss: 0.5909 - io_u_7: 0.8683 - accuracy: 0.8842 - mean_io_u_7: 0.5834 - val_loss: 0.6369 - val_io_u_7: 0.8586 - val_accuracy: 0.8747 - val_mean_io_u_7: 0.5914 - lr: 1.0000e-03\n",
            "Epoch 25/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6222 - io_u_7: 0.8852 - accuracy: 0.8875 - mean_io_u_7: 0.6061\n",
            "Epoch 25: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6222 - io_u_7: 0.8852 - accuracy: 0.8875 - mean_io_u_7: 0.6061 - val_loss: 0.5622 - val_io_u_7: 0.8855 - val_accuracy: 0.9116 - val_mean_io_u_7: 0.6418 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6491 - io_u_7: 0.8896 - accuracy: 0.8850 - mean_io_u_7: 0.6055\n",
            "Epoch 26: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 459ms/step - loss: 0.6491 - io_u_7: 0.8896 - accuracy: 0.8850 - mean_io_u_7: 0.6055 - val_loss: 0.6017 - val_io_u_7: 0.8647 - val_accuracy: 0.8828 - val_mean_io_u_7: 0.6058 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6325 - io_u_7: 0.8927 - accuracy: 0.8895 - mean_io_u_7: 0.6087\n",
            "Epoch 27: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 451ms/step - loss: 0.6325 - io_u_7: 0.8927 - accuracy: 0.8895 - mean_io_u_7: 0.6087 - val_loss: 0.5904 - val_io_u_7: 0.8953 - val_accuracy: 0.9028 - val_mean_io_u_7: 0.6153 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6347 - io_u_7: 0.8840 - accuracy: 0.8860 - mean_io_u_7: 0.5982\n",
            "Epoch 28: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 458ms/step - loss: 0.6347 - io_u_7: 0.8840 - accuracy: 0.8860 - mean_io_u_7: 0.5982 - val_loss: 0.6365 - val_io_u_7: 0.9018 - val_accuracy: 0.9025 - val_mean_io_u_7: 0.6440 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6438 - io_u_7: 0.8941 - accuracy: 0.8900 - mean_io_u_7: 0.6112\n",
            "Epoch 29: val_loss did not improve from 0.54992\n",
            "56/56 [==============================] - 25s 455ms/step - loss: 0.6438 - io_u_7: 0.8941 - accuracy: 0.8900 - mean_io_u_7: 0.6112 - val_loss: 0.5884 - val_io_u_7: 0.9106 - val_accuracy: 0.9121 - val_mean_io_u_7: 0.6427 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6456 - io_u_7: 0.8756 - accuracy: 0.8809 - mean_io_u_7: 0.5874\n",
            "Epoch 30: val_loss improved from 0.54992 to 0.54890, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 462ms/step - loss: 0.6456 - io_u_7: 0.8756 - accuracy: 0.8809 - mean_io_u_7: 0.5874 - val_loss: 0.5489 - val_io_u_7: 0.9116 - val_accuracy: 0.9229 - val_mean_io_u_7: 0.6673 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6317 - io_u_7: 0.8897 - accuracy: 0.8902 - mean_io_u_7: 0.6061\n",
            "Epoch 31: val_loss did not improve from 0.54890\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6317 - io_u_7: 0.8897 - accuracy: 0.8902 - mean_io_u_7: 0.6061 - val_loss: 0.6600 - val_io_u_7: 0.9082 - val_accuracy: 0.9144 - val_mean_io_u_7: 0.6524 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6516 - io_u_7: 0.8941 - accuracy: 0.8872 - mean_io_u_7: 0.6102\n",
            "Epoch 32: val_loss improved from 0.54890 to 0.54566, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 25s 459ms/step - loss: 0.6516 - io_u_7: 0.8941 - accuracy: 0.8872 - mean_io_u_7: 0.6102 - val_loss: 0.5457 - val_io_u_7: 0.8927 - val_accuracy: 0.9081 - val_mean_io_u_7: 0.6312 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6382 - io_u_7: 0.8868 - accuracy: 0.8869 - mean_io_u_7: 0.6037\n",
            "Epoch 33: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 454ms/step - loss: 0.6382 - io_u_7: 0.8868 - accuracy: 0.8869 - mean_io_u_7: 0.6037 - val_loss: 0.5601 - val_io_u_7: 0.8868 - val_accuracy: 0.9007 - val_mean_io_u_7: 0.6360 - lr: 1.0000e-05\n",
            "Epoch 34/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6230 - io_u_7: 0.8720 - accuracy: 0.8835 - mean_io_u_7: 0.5854\n",
            "Epoch 34: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6230 - io_u_7: 0.8720 - accuracy: 0.8835 - mean_io_u_7: 0.5854 - val_loss: 0.5609 - val_io_u_7: 0.8387 - val_accuracy: 0.8722 - val_mean_io_u_7: 0.5827 - lr: 1.0000e-05\n",
            "Epoch 35/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6376 - io_u_7: 0.8825 - accuracy: 0.8861 - mean_io_u_7: 0.5990\n",
            "Epoch 35: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 453ms/step - loss: 0.6376 - io_u_7: 0.8825 - accuracy: 0.8861 - mean_io_u_7: 0.5990 - val_loss: 0.5920 - val_io_u_7: 0.8800 - val_accuracy: 0.8872 - val_mean_io_u_7: 0.6226 - lr: 1.0000e-05\n",
            "Epoch 36/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6285 - io_u_7: 0.8861 - accuracy: 0.8882 - mean_io_u_7: 0.6039\n",
            "Epoch 36: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6285 - io_u_7: 0.8861 - accuracy: 0.8882 - mean_io_u_7: 0.6039 - val_loss: 0.5630 - val_io_u_7: 0.8641 - val_accuracy: 0.8848 - val_mean_io_u_7: 0.6303 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6053 - io_u_7: 0.8721 - accuracy: 0.8850 - mean_io_u_7: 0.5884\n",
            "Epoch 37: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6053 - io_u_7: 0.8721 - accuracy: 0.8850 - mean_io_u_7: 0.5884 - val_loss: 0.5940 - val_io_u_7: 0.9099 - val_accuracy: 0.9259 - val_mean_io_u_7: 0.6490 - lr: 1.0000e-06\n",
            "Epoch 38/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6454 - io_u_7: 0.8890 - accuracy: 0.8913 - mean_io_u_7: 0.6104\n",
            "Epoch 38: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 449ms/step - loss: 0.6454 - io_u_7: 0.8890 - accuracy: 0.8913 - mean_io_u_7: 0.6104 - val_loss: 0.5570 - val_io_u_7: 0.9059 - val_accuracy: 0.9059 - val_mean_io_u_7: 0.6622 - lr: 1.0000e-06\n",
            "Epoch 39/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6362 - io_u_7: 0.8931 - accuracy: 0.8913 - mean_io_u_7: 0.6117\n",
            "Epoch 39: val_loss did not improve from 0.54566\n",
            "56/56 [==============================] - 25s 451ms/step - loss: 0.6362 - io_u_7: 0.8931 - accuracy: 0.8913 - mean_io_u_7: 0.6117 - val_loss: 0.6124 - val_io_u_7: 0.8965 - val_accuracy: 0.9014 - val_mean_io_u_7: 0.6335 - lr: 1.0000e-06\n",
            "Epoch 40/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6220 - io_u_7: 0.8963 - accuracy: 0.8949 - mean_io_u_7: 0.6193\n",
            "Epoch 40: val_loss improved from 0.54566 to 0.51189, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 25s 461ms/step - loss: 0.6220 - io_u_7: 0.8963 - accuracy: 0.8949 - mean_io_u_7: 0.6193 - val_loss: 0.5119 - val_io_u_7: 0.8584 - val_accuracy: 0.8841 - val_mean_io_u_7: 0.6488 - lr: 1.0000e-06\n",
            "Epoch 41/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6284 - io_u_7: 0.8795 - accuracy: 0.8789 - mean_io_u_7: 0.5904\n",
            "Epoch 41: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6284 - io_u_7: 0.8795 - accuracy: 0.8789 - mean_io_u_7: 0.5904 - val_loss: 0.5363 - val_io_u_7: 0.8182 - val_accuracy: 0.8612 - val_mean_io_u_7: 0.5783 - lr: 1.0000e-06\n",
            "Epoch 42/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6257 - io_u_7: 0.8876 - accuracy: 0.8864 - mean_io_u_7: 0.6027\n",
            "Epoch 42: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 456ms/step - loss: 0.6257 - io_u_7: 0.8876 - accuracy: 0.8864 - mean_io_u_7: 0.6027 - val_loss: 0.5995 - val_io_u_7: 0.9110 - val_accuracy: 0.9222 - val_mean_io_u_7: 0.6519 - lr: 1.0000e-06\n",
            "Epoch 43/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6089 - io_u_7: 0.8712 - accuracy: 0.8809 - mean_io_u_7: 0.5835\n",
            "Epoch 43: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6089 - io_u_7: 0.8712 - accuracy: 0.8809 - mean_io_u_7: 0.5835 - val_loss: 0.5939 - val_io_u_7: 0.8873 - val_accuracy: 0.8989 - val_mean_io_u_7: 0.6408 - lr: 1.0000e-06\n",
            "Epoch 44/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6253 - io_u_7: 0.8788 - accuracy: 0.8838 - mean_io_u_7: 0.5955\n",
            "Epoch 44: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6253 - io_u_7: 0.8788 - accuracy: 0.8838 - mean_io_u_7: 0.5955 - val_loss: 0.5314 - val_io_u_7: 0.8725 - val_accuracy: 0.9026 - val_mean_io_u_7: 0.6466 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6114 - io_u_7: 0.8874 - accuracy: 0.8913 - mean_io_u_7: 0.6065\n",
            "Epoch 45: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 448ms/step - loss: 0.6114 - io_u_7: 0.8874 - accuracy: 0.8913 - mean_io_u_7: 0.6065 - val_loss: 0.5782 - val_io_u_7: 0.8897 - val_accuracy: 0.9019 - val_mean_io_u_7: 0.6337 - lr: 1.0000e-07\n",
            "Epoch 46/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6392 - io_u_7: 0.8868 - accuracy: 0.8857 - mean_io_u_7: 0.6039\n",
            "Epoch 46: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 453ms/step - loss: 0.6392 - io_u_7: 0.8868 - accuracy: 0.8857 - mean_io_u_7: 0.6039 - val_loss: 0.5500 - val_io_u_7: 0.9116 - val_accuracy: 0.9290 - val_mean_io_u_7: 0.6588 - lr: 1.0000e-07\n",
            "Epoch 47/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6575 - io_u_7: 0.8928 - accuracy: 0.8893 - mean_io_u_7: 0.6081\n",
            "Epoch 47: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 452ms/step - loss: 0.6575 - io_u_7: 0.8928 - accuracy: 0.8893 - mean_io_u_7: 0.6081 - val_loss: 0.5816 - val_io_u_7: 0.8696 - val_accuracy: 0.8827 - val_mean_io_u_7: 0.6546 - lr: 1.0000e-07\n",
            "Epoch 48/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6448 - io_u_7: 0.8927 - accuracy: 0.8878 - mean_io_u_7: 0.6095\n",
            "Epoch 48: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6448 - io_u_7: 0.8927 - accuracy: 0.8878 - mean_io_u_7: 0.6095 - val_loss: 0.6126 - val_io_u_7: 0.8824 - val_accuracy: 0.8847 - val_mean_io_u_7: 0.6418 - lr: 1.0000e-07\n",
            "Epoch 49/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6289 - io_u_7: 0.8792 - accuracy: 0.8821 - mean_io_u_7: 0.5917\n",
            "Epoch 49: val_loss did not improve from 0.51189\n",
            "56/56 [==============================] - 25s 450ms/step - loss: 0.6289 - io_u_7: 0.8792 - accuracy: 0.8821 - mean_io_u_7: 0.5917 - val_loss: 0.5273 - val_io_u_7: 0.9165 - val_accuracy: 0.9345 - val_mean_io_u_7: 0.6574 - lr: 1.0000e-08\n",
            "Epoch 50/50\n",
            "56/56 [==============================] - ETA: 0s - loss: 0.6192 - io_u_7: 0.8766 - accuracy: 0.8829 - mean_io_u_7: 0.5900\n",
            "Epoch 50: val_loss improved from 0.51189 to 0.49314, saving model to /content/model_checkpoint/model_checkpoint_patch.h5\n",
            "56/56 [==============================] - 26s 462ms/step - loss: 0.6192 - io_u_7: 0.8766 - accuracy: 0.8829 - mean_io_u_7: 0.5900 - val_loss: 0.4931 - val_io_u_7: 0.8543 - val_accuracy: 0.8743 - val_mean_io_u_7: 0.6440 - lr: 1.0000e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = tf.keras.models.load_model(model_file)\n",
        "# model_loaded.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "8lRBX8BontSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(metric_name, title, ylim=5):\n",
        "#   '''plots a given metric from the model history'''\n",
        "    plt.title(title)\n",
        "    plt.ylim(0,ylim)\n",
        "    plt.plot(model_history.history[metric_name],color='blue',label=metric_name)\n",
        "    plt.plot(model_history.history['val_' + metric_name],color='green',label='val_' + metric_name)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JsqTr69QntSs"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "trusted": true,
        "id": "yRL01QrPntSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "fig, axes = plt.subplots(1, 2)\n",
        "axes[0].plot(x, y1)\n",
        "axes[0].set_title('Plot 1')"
      ],
      "metadata": {
        "id": "zNxFzPQLntSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, loss, 'r', label='Training loss')\n",
        "plt.plot(history.epoch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "qLWfYLXXntSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, accuracy, 'r', label='Training Accuracy')\n",
        "plt.plot(history.epoch, val_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "1tXlIVoOntSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "miou = history.history['mean_io_u_2']\n",
        "val_miou = history.history['val_mean_io_u_2']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, miou, 'r', label='Training miou')\n",
        "plt.plot(history.epoch, val_miou, 'b', label='Validation miou')\n",
        "plt.title('Training and Validation miou')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('miou Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "OoGXR-j7ntSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Prediction"
      ],
      "metadata": {
        "id": "XY7zvP_HntSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir kaggle/working/aerialimage/test_input/input_data"
      ],
      "metadata": {
        "trusted": true,
        "id": "0b8PlLtFntSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move input images to the folder\n",
        "\n",
        "org_test_input = '/kaggle/input/aerialimagedataset/AerialImageDataset/test/images/'\n",
        "new_test_input = '/kaggle/working/aerialimage/test_input/input_data'\n",
        "\n",
        "\n",
        "input_img_paths = []\n",
        "\n",
        "for dirname, _, filenames in os.walk(org_test_input):\n",
        "    for filename in filenames:\n",
        "        input_img_paths.append(os.path.join(dirname, filename))\n",
        "\n",
        "input_img_paths = sorted(input_img_paths)\n",
        "\n",
        "random.Random(23).shuffle(input_img_paths)\n",
        "    \n",
        "input_img_paths[0:2]"
      ],
      "metadata": {
        "trusted": true,
        "id": "wSUiU0SZntSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy 40 input images to test folder\n",
        "\n",
        "for file in input_img_paths:\n",
        "    shutil.copy(file, new_test_input)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ncETmcTdntSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_target_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "trusted": true,
        "id": "I2XgwjFtntSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Prediction Utilities\n",
        "\n",
        "# def create_mask(pred_mask):\n",
        "# #   '''\n",
        "# #   Creates the segmentation mask by getting the channel with the highest probability. Remember that we\n",
        "# #   have 3 channels in the output of the UNet. For each pixel, the predicition will be the channel with the\n",
        "# #   highest probability.\n",
        "# #   '''\n",
        "#     pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "#     pred_mask = pred_mask[..., tf.newaxis]\n",
        "#     return pred_mask[0].numpy()\n",
        "\n",
        "# def make_predictions(image, num=1):\n",
        "# #   '''\n",
        "# #   Feeds an image to a model and returns the predicted mask.\n",
        "# #   '''\n",
        "\n",
        "#     pred_mask = model.predict(image)\n",
        "#     pred_mask = create_mask(pred_mask)\n",
        "\n",
        "#     return pred_mask"
      ],
      "metadata": {
        "trusted": true,
        "id": "jmK0MZLfntS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the filename in the directory\n",
        "\n",
        "def read_file(directory):\n",
        " blind_test = []\n",
        " for dirname, _, filenames in os.walk(directory):\n",
        " for filename in filenames:\n",
        " blind_test.append(os.path.join(dirname, filename))\n",
        " blind_test = sorted(blind_test)\n",
        " return blind_test\n",
        "\n",
        "# build the dataset using list of filenames and target image size\n",
        "def build_dataset(dir_list, img_size):\n",
        " num_imgs = len(dir_list)\n",
        " test_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
        "\n",
        " for i in range(len(dir_list)):\n",
        " test_imgs[i] = img_to_array(load_img(dir_list[i], target_size=img_size))\n",
        " return test_imgs\n",
        "\n",
        "img_size = (512,512)\n",
        "directory_input = '/kaggle/working/aerialimage/val_input/input_data'\n",
        "directory_target = '/kaggle/working/aerialimage/val_target/target_data'\n",
        "\n",
        "\n",
        "val_input_dir = read_file(directory_input)\n",
        "val_target_dir = read_file(directory_target)\n",
        "\n",
        "\n",
        "val_input = build_dataset(val_input_dir, img_size)\n",
        "val_target = build_dataset(val_target_dir, img_size)\n",
        "\n",
        "\n",
        "print(\"Shape of val input data:\", val_input.shape)\n",
        "print(\"Shape of val input target:\", val_target.shape)\n"
      ],
      "metadata": {
        "id": "D3l41Qy2ntS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_data(test_imgs , target_imgs, num1, num2, model_load):\n",
        " plt.figure(figsize=(100,100))\n",
        " s = num1\n",
        " i = num2\n",
        "\n",
        " count = 1\n",
        "\n",
        " for k in range(s,i,1):\n",
        " input_image = test_imgs[k]\n",
        " target_image = target_imgs[k]\n",
        "\n",
        " prediction = model_load.predict(np.expand_dims(input_image, 0))[0]\n",
        " pred_threshold = prediction > 0.5\n",
        " pred_threshold = pred_threshold * 255\n",
        "\n",
        " plt.subplot(6,6,3*count-2)\n",
        " plt.axis(\"off\")\n",
        " plt.imshow(array_to_img(input_image))\n",
        "\n",
        " plt.subplot(6,6,3*count-1)\n",
        " plt.axis(\"off\")\n",
        " plt.imshow(array_to_img(target_image), cmap=\"gray\")\n",
        " plt.tight_layout()\n",
        "\n",
        "\n",
        " plt.subplot(6,6,3*count)\n",
        " plt.axis(\"off\")\n",
        " plt.imshow(pred_threshold, cmap=\"gray\")\n",
        "\n",
        " count += 1\n",
        "\n",
        " plt.show()\n",
        " plt.tight_layout()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WxIAfHASntS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(display_list,titles=[], display_string=None):\n",
        "#   '''displays a list of images/masks'''\n",
        "\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(titles[i])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        if display_string and i == 1:\n",
        "              plt.xlabel(display_string, fontsize=12)\n",
        "        img_arr = tf.keras.preprocessing.image.array_to_img(display_list[i])\n",
        "        plt.imshow(img_arr)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "MFwToZ2DntS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "    if dataset:\n",
        "        for imagein dataset.take(num):\n",
        "            pred_mask = model.predict(image)\n",
        "            display([image[0], create_mask(pred_mask)])"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZLc4NreXntS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}