{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory to move files\n",
    "\n",
    "!mkdir /kaggle/working/aerialimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19, VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folders to move train and validation files\n",
    "\n",
    "!mkdir /kaggle/working/aerialimage/train_input\n",
    "!mkdir /kaggle/working/aerialimage/train_target\n",
    "\n",
    "!mkdir /kaggle/working/aerialimage/val_input\n",
    "!mkdir /kaggle/working/aerialimage/val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folders to move train and validation files\n",
    "\n",
    "!mkdir /kaggle/working/aerialimage/train_input/input_data\n",
    "!mkdir /kaggle/working/aerialimage/train_target/target_data\n",
    "\n",
    "!mkdir /kaggle/working/aerialimage/val_input/input_data\n",
    "!mkdir /kaggle/working/aerialimage/val_target/target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move input images to the folder\n",
    "\n",
    "org_train_input = '/kaggle/input/aerialimagedataset/AerialImageDataset/train/images/'\n",
    "new_train_input = '/kaggle/working/aerialimage/train_input/input_data'\n",
    "new_val_input = '/kaggle/working/aerialimage/val_input/input_data'\n",
    "\n",
    "input_img_paths = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(org_train_input):\n",
    "    for filename in filenames:\n",
    "        input_img_paths.append(os.path.join(dirname, filename))\n",
    "\n",
    "input_img_paths = sorted(input_img_paths)\n",
    "\n",
    "random.Random(23).shuffle(input_img_paths)\n",
    "    \n",
    "input_img_paths[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy 40 input images to validation folder\n",
    "\n",
    "val_num = 40\n",
    "\n",
    "for file in input_img_paths[:val_num]:\n",
    "    shutil.copy(file, new_val_input)\n",
    "    \n",
    "for file in input_img_paths[val_num:]:\n",
    "    shutil.copy(file, new_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move target images to the folder\n",
    "\n",
    "org_train_target = '/kaggle/input/aerialimagedataset/AerialImageDataset/train/gt/'\n",
    "new_train_target = '/kaggle/working/aerialimage/train_target/target_data'\n",
    "new_val_target = '/kaggle/working/aerialimage/val_target/target_data'\n",
    "\n",
    "target_img_paths = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(org_train_target):\n",
    "    for filename in filenames:\n",
    "        target_img_paths.append(os.path.join(dirname, filename))\n",
    "\n",
    "target_img_paths = sorted(target_img_paths)\n",
    "\n",
    "random.Random(23).shuffle(target_img_paths)\n",
    "\n",
    "target_img_paths[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy 40 target images to validation folder\n",
    "\n",
    "for file in target_img_paths[:val_num]:\n",
    "    shutil.copy(file, new_val_target)\n",
    "    \n",
    "for file in target_img_paths[val_num:]:\n",
    "    shutil.copy(file, new_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether folder names in input and target folders match\n",
    "\n",
    "new_train_target = '/kaggle/working/aerialimage/train_target/target_data'\n",
    "new_val_target = '/kaggle/working/aerialimage/val_target/target_data'\n",
    "\n",
    "new_train_input = '/kaggle/working/aerialimage/train_input/input_data'\n",
    "new_val_input = '/kaggle/working/aerialimage/val_input/input_data'\n",
    "\n",
    "i = 0\n",
    "\n",
    "for dirname, _, filenames in os.walk(new_train_input):\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        i += 1\n",
    "        if i == 5:\n",
    "            break\n",
    "        \n",
    "\n",
    "k = 0\n",
    "\n",
    "for dirname, _, filenames in os.walk(new_train_target):\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        k += 1\n",
    "        if k == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an image generator / data augmentation pipeline \n",
    "# augment data in train dataset only\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "TARGET_SIZE = (512,512)\n",
    "seed = 23\n",
    "\n",
    "train_datagen = ImageDataGenerator(samplewise_std_normalization=False, \n",
    "                                   horizontal_flip = True, \n",
    "                                   vertical_flip = False, \n",
    "                                   height_shift_range = 0.1, \n",
    "                                   width_shift_range = 0.1, \n",
    "                                   rotation_range = 3, \n",
    "                                   shear_range = 0.01,\n",
    "                                   fill_mode = 'nearest',\n",
    "                                   zoom_range = 0.05, \n",
    "                                   zca_whitening = True,\n",
    "                                   zca_epsilon=1e-5, \n",
    "                                   )\n",
    "\n",
    "\n",
    "target_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    samplewise_std_normalization=False, \n",
    "                                    horizontal_flip = True, \n",
    "                                    vertical_flip = False, \n",
    "                                    height_shift_range = 0.1, \n",
    "                                    width_shift_range = 0.1, \n",
    "                                    rotation_range = 3, \n",
    "                                    shear_range = 0.01,\n",
    "                                    fill_mode = 'nearest',\n",
    "                                    zoom_range = 0.05,\n",
    "                                    zca_whitening = True,\n",
    "                                    zca_epsilon=1e-5, \n",
    "                                   )\n",
    "\n",
    "val_input_datagen = ImageDataGenerator()\n",
    "\n",
    "val_target_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data augmentation pipeline and start loading train data from folders\n",
    "\n",
    "train_generator_input = train_datagen.flow_from_directory(\n",
    "    '/kaggle/working/aerialimage/train_input',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    seed = seed\n",
    "\n",
    ")\n",
    "\n",
    "train_generator_output = target_datagen.flow_from_directory(\n",
    "    '/kaggle/working/aerialimage/train_target',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    color_mode=\"grayscale\",\n",
    "    seed = seed\n",
    ")\n",
    "\n",
    "train_generator = zip(train_generator_input, train_generator_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data augmentation pipeline and start loading validation data from folders\n",
    "\n",
    "val_generator_input = val_input_datagen.flow_from_directory(\n",
    "    '/kaggle/working/aerialimage/val_input',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    seed = seed\n",
    "\n",
    ")\n",
    "\n",
    "val_generator_output = val_target_datagen.flow_from_directory(\n",
    "    '/kaggle/working/aerialimage/val_target',\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    color_mode=\"grayscale\",\n",
    "    seed = seed\n",
    ")\n",
    "\n",
    "val_generator = zip(val_generator_input, val_generator_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define architecture of VGG19 model\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\",kernel_initializer = 'he_normal')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer = 'he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_vgg19_unet(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Pre-trained VGG19 Model \"\"\"\n",
    "    vgg19 = VGG19(include_top=False, weights=\"/kaggle/input/vgg19weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\", input_tensor=inputs)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = vgg19.get_layer(\"block1_conv2\").output         ## (512 x 512)\n",
    "    s2 = vgg19.get_layer(\"block2_conv2\").output         ## (256 x 256)\n",
    "    s3 = vgg19.get_layer(\"block3_conv4\").output         ## (128 x 128)\n",
    "    s4 = vgg19.get_layer(\"block4_conv4\").output         ## (64 x 64)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = vgg19.get_layer(\"block5_conv4\").output         ## (32 x 32)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
    "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
    "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
    "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
    "\n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and output architecture\n",
    "\n",
    "input_shape = TARGET_SIZE + (3,)\n",
    "model = build_vgg19_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model and set up the callback to save the model as we train\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "callbacks=[keras.callbacks.ModelCheckpoint(\"VGG19_5DEC2022.keras\", save_best_only = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs=100, \n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    steps_per_epoch = 2*140/BATCH_SIZE,\n",
    "                    validation_steps = 40/BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
